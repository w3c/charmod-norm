<!DOCTYPE html>
<html dir="ltr" lang="en">
  <head>
    <meta charset="UTF-8">
    
    <!--
    Editor's note: the current list of Unicode characters used in this document is:
    
    U+0130 U+0131 U+0133 U+0141 U+017E U+01C4 U+01C5 U+01C6 U+01FA U+0300 U+0301 U+0307 U+030A U+0323 U+0327 U+0342 U+0398 U+03A1 U+03A9 U+03B1 U+03B8 U+03B9 U+03C9 U+0414 U+0420 U+0434 U+0627 U+0628 U+062A U+0646 U+0647 U+0654 U+08A1 U+0915 U+0921 U+0928 U+092F U+093F U+0942 U+094B U+1100 U+1161 U+1780 U+178A U+178F U+17D2 U+1E9E U+1F23 U+1F7C U+1F93 U+1F9B U+1FB6 U+1FB7 U+1FF2 U+200B U+200C U+200D U+2014 U+2019 U+2044 U+2079 U+2089 U+208A U+20AC U+210C U+210D U+2126 U+212B U+215F U+2189 U+21D2 U+2260 U+2460 U+2469 U+2474 U+2488 U+24B6 U+25CC U+2EF3 U+3002 U+30A2 U+30AB U+30C8 U+30D1 U+30E6 U+30F3 U+30FC U+3250 U+329E U+3300 U+3350 U+3389 U+3392 U+5370 U+9F9F U+AC00 U+1F1F2 U+1F1FF U+1F3F4 U+1F3FB U+1F3FC U+1F3FD U+1F3FE U+1F3FF U+1F467 U+1F468 U+1F469 U+1F46A U+E0062 U+E0063 U+E0067 U+E0073 U+E0074 U+E007F U+FE37 U+FEE9 U+FEEA U+FEEB U+FEEC U+FF21 U+FF5B U+FF76
    -->
    
    
    <title>Character Model for the World Wide Web: String Matching</title>
    <link rel="canonical" href="https://www.w3.org/TR/charmod-norm/"/>
    <!-- local styles. Includes the styles from https://www.w3.org/International/i18n-activity/guidelines/editing -->
    <link rel="stylesheet" href="local.css">
	<script src="https://www.w3.org/Tools/respec/respec-w3c" async class="remove"></script>
    <script class="remove">
      var respecConfig = {
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:				"ED",
          //publishDate:  			"2019-02-04",
          //previousPublishDate:  	"2019-02-04",
          //previousMaturity:  		"WG-NOTE",

          noRecTrack:           true,
          shortName:            "charmod-norm",
          copyrightStart: 		"2004",
          edDraftURI:   		"https://w3c.github.io/charmod-norm/",

          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              { name: "Addison Phillips", 
                company: "Amazon.com",
				w3cid: 33573 },
          ],

          // authors, add as many as you like. 
          //authors:  [
          //    { name: "Your Name", url: "http://example.org/",
          //      company: "Your Company", companyURL: "http://example.com/" },
          //],
          
          group:        "i18n",
          github:       "w3c/charmod-norm",
          
		  localBiblio: {
		  "UTS18": {
		    title: "Unicode Technical Standard #18: Unicode Regular Expressions",
			href: "https://unicode.org/reports/tr18/",
			authors: [ "Mark Davis", "Andy Heninger" ]
		},
		
		"ISO10646": {
			title: "Information Technology - Universal Multiple- Octet Coded CharacterSet (UCS) - Part 1: Architecture and Basic Multilingual Plane",
			authors: [ "ISO/IEC10646-1:1993" ],
			note: "The current specification also takes into consideration the first five amendments to ISO/IEC 10646-1:1993. Useful roadmaps (http://www.egt.ie/standards/iso10646/ucs-roadmap.html) show which scripts sit at which numeric ranges."
		},
		
		"UTS10": {
			title: "Unicode Technical Standard #10: Unicode Collation Algorithm",
			href: "https://www.unicode.org/reports/tr10/",
			authors: [ "Mark Davis", "Ken Whistler", "Markus Scherer" ]
		},

        "UAX9": {
            title: "Unicode Standard Annex #9: Unicode Bidirectional Algorithm",
            href: "https://unicode.org/reports/tr9/",
            authors: [ "Mark Davis", "Aharon Lahnin", "Andrew Glass" ]
        },
		
		"UAX11": {
		    title: "Unicode Standard Annex #11: East Asian Width",
		    href: "https://www.unicode.org/reports/tr11/",
		    authors: [ "Ken Lunde 小林劍" ]
		},
		
		"UAX29": {
			title: "Unicode Standard Annex #29: Unicode Text Segmentation",
			href: "https://www.unicode.org/reports/tr29/",
			authors: [ "Mark Davis" ]
		},
		
		"UTS39": {
		    title: "Unicode Technical Standard #39: Unicode Security Mechanisms",
		    href: "https://www.unicode.org/reports/tr39/",
		    authors: [ "Mark Davis", "Michel Suignard" ]
		},
		
		"UTR36": {
			title: "Unicode Technical Report #36: Unicode Security Considerations",
			href: "https://www.unicode.org/reports/tr36/",
			authors: [ "Mark Davis", "Michel Suignard" ]
		},
		
		"UTR50": {
		    title: "Unicode Technical Report #50: Unicode Vertical Text Layout",
		    href: "https://www.unicode.org/reports/tr50/",
		    authors: [ "Koji Ishii 石井宏治" ]
		},

		"UTR51": {
		    title: "Unicode Technical Report #51: Unicode Emoji",
		    href: "https://www.unicode.org/reports/tr51/",
		    authors: [ "Mark Davis", "Peter Edberg" ]
	    },
	    
	    "STRING-SEARCH": {
			title: "Character Model for the World Wide Web: String Searching",
			href: "https://w3c.github.io/string-search/",
			authors: [ "Addison Phillips" ]
		},
		
		"ASCII": {
		    title: "ISO/IEC 646:1991, Information technology -- ISO 7-bit coded character set for information interchange",
		    href:  "http://www.ecma-international.org/publications/standards/Ecma-006.htm",
		    isoNumber: "ISO/IEC 646:1991",
		    note:  "This standard defines an International Reference Version (IRV) which corresponds exactly to what is widely known as ASCII or US-ASCII. ISO/IEC 646 was based on the earlier standard ECMA-6. ECMA has maintained its standard up to date with respect to ISO/IEC 646 and makes an electronic copy available at http://www.ecma-international.org/publications/standards/Ecma-006.htm "
	    },
	
	}
		  
      };
	  

</script>
</head>

<body>
<div id="abstract">
<p>This document builds upon <cite>Character Model for the World Wide Web 1.0: Fundamentals </cite>[[CHARMOD]] to provide authors of specifications, software developers, and content developers a common reference on string identity matching on the World Wide Web and thereby increase interoperability.</p>
</div>
<div id="sotd">
<p>To make it easier to track comments, please raise separate issues or emails for each comment, and point to the section you are commenting on using a URL.</p>


</div>
    <section id="intro">
      <h2>Introduction</h2>
      <section id="goals">
        <h3>Goals and Scope</h3>
        
        <p>The goal of the Character Model for the World Wide Web is to facilitate use of the Web by all people, regardless of their language, script, writing system, or cultural conventions, in accordance with the <a href="https://www.w3.org/Consortium/mission"><cite>W3C goal of universal access</cite></a>. One basic prerequisite to achieve this goal is to be able to transmit and process the characters used around the world in a well-defined and well-understood way.</p>
        
        <p class="note">This document builds on <cite>Character Model for the World Wide Web: Fundamentals</cite> [[CHARMOD]]. Understanding the concepts in that document are important to being able to understand and apply this document successfully.</p>
        
        <p>This part of the Character Model for the World Wide Web covers string 
		matching—the process by which a specification or implementation defines 
		whether two string values are the same or different from one another. It 
		describes the ways in which texts that are semantically equivalent can 
		be encoded differently and the impact this has on matching operations 
		important to formal languages (such as those used in the formats and 
		protocols that make up the Web).</p>
        <p>The main target audience of this specification is W3C specification
          developers. This specification and parts of it can be referenced from
          other W3C specifications and it defines conformance criteria for W3C
          specifications, as well as other specifications.</p>
        <p>Other audiences of this specification include software developers,
          content developers, and authors of specifications outside the W3C.
          Software developers and content developers implement and use W3C
          specifications. This specification defines some conformance criteria
          for implementations (software) and content that implement and use W3C
          specifications. It also helps software developers and content
          developers to understand the character-related provisions in W3C
          specifications.</p>
        <p>The character model described in this specification provides authors
          of specifications, software developers, and content developers with a
          common reference for consistent, interoperable text manipulation on
          the World Wide Web. Working together, these three groups can build a
          globally accessible Web.</p>
      </section>
      <section id="structure">
        <h3>Structure of this Document</h3>
        <p>This document defines one of the basic building blocks for the Web related
          to this problem by defining rules and processes for String
          Identity Matching in document formats. These rules are designed for
          the identifiers and structural markup (<a href="#def_syntactic_content" class="termref">syntactic content</a>) 
		used in document formats to ensure consistent processing of each and are 
		targeted to Specification writers. This
          section is targeted to implementers.</p>
        <p>This document is divided into two main sections.</p>
        <p>The <a href="#problemStatement">first section</a> lays out the
          problems involved in string matching; the effects of Unicode and case
          folding on these problems; and outlines the various issues and
          normalization mechanisms that might be used to address these issues.</p>
        <p>The <a href="#identityMatching">second section</a> provides
          requirements and recommendations for string identity matching for use
          in <span class="qterm">formal languages</span>, such as many of the
          document formats defined in W3C Specifications. This primarily is
          concerned with making the Web functional and providing document
          authors with consistent results. </p>
      </section>
      <section id="background">
        <h3>Background</h3>
        <p>This section provides some historical background on the topics
          addressed in this specification.</p>
        <p>At the core of the character model is the Universal Character Set
          (UCS), defined jointly by the <cite>Unicode Standard</cite>
          [[!Unicode]] and ISO/IEC 10646 [[!ISO10646]]. In this document, <dfn>Unicode</dfn>
          is used as a synonym for the Universal Character Set. A successful
          character model allows Web documents authored in the world's writing
          systems, scripts, and languages (and on different platforms) to be
          exchanged, read, and searched by the Web's users around the world.</p>
        <p>The first few chapters of the <cite>Unicode Standard</cite>
          [[!Unicode]] provide useful background reading.</p>
        <p>For information about the requirements that informed the development
          of important parts of this specification, see <cite>Requirements for
            String Identity Matching and String Indexing</cite> [[CHARREQ]].</p>
      </section>
      <section id="terminology">
        <h3>Terminology and Notation</h3>
        
        <p>This section contains terminology and notation specific to this document.</p>
        
        <p>The Web is built on text-based formats and protocols. In order to
          describe string matching or searching effectively, it is necessary to
          establish terminology that allows us to talk about the different kinds
          of text within a given format or protocol, as the requirements and
          details vary significantly. </p>
          
        <p>A <dfn data-lt="Unicode code point|Unicode code points|code point|code points">Unicode code point</dfn> (or "code point") refers to the numeric value assigned to each Unicode character. Unicode code points range from <code class="kw" translate="no">0</code> to <code class="kw" translate="no">0x10FFFF</code>. (See Section 4.1 in [[!CHARMOD]] for a deeper discussion of character encoding terminology.)</p>
          
        <p>Unicode code points are denoted as <code class="kw" translate="no">U+<em>hhhh</em></code>, where <code class="kw" translate="no"><em>hhhh</em></code> is a sequence of at least four, and at most six hexadecimal digits. For example, the character <span class="codepoint"><span lang="en">&#x20AC;</span> [<span class="uname">U+20AC EURO SIGN</span>]</span> has the code point <span class="uname" translate="no">U+20AC</span>, while the character <span class="codepoint">&#x1f63a;</span> [<span class="uname">U+1F63A SMILING CAT FACE WITH OPEN MOUTH</span>] has the code point <span class="uname" translate="no">U+1F63A</span>.</p>
          
        <p>Some characters used in this document's examples might not appear as intended on your specific device or display. Usually this is due to lack of a script-specific font installed locally or due to other limitations of your specific rendering system. This document uses a Webfont to provide fallback glyphs for many of the non-Latin characters, but your device might not support displaying the font. To the degree possible, the editors have tried to ensure that the examples nevertheless remain understandable.</p>
          
        <p>A <dfn data-lt="legacy character encoding|legacy character encodings">legacy character encoding</dfn> is a character encoding form that does not encode the full repertoire of characters in the Unicode character set.</p>
          
                   
        <p>A <dfn data-lt="transcoder|transcoders">transcoder</dfn> is a process that converts 
		text between two character encodings. Most commonly in this document it 
		refers to a process that converts from a <a>legacy character encoding</a> 
        to a <a href="https://www.w3.org/TR/2005/REC-charmod-20050215/#Unicode_Encoding_Form">Unicode encoding form</a>, 
		such as UTF-8.</p>
		
		<p><dfn data-lt="natural language">Natural language</dfn> is the spoken, written, or signed communications used by human beings (see also <a href="https://www.w3.org/TR/ltli/#dfn-natural-language">here</a> [[LTLI]])</p>
		
        <p><dfn data-lt="syntactic content" id="def_syntactic_content">Syntactic content</dfn> is any text in a document format or protocol that belongs to the structure of the format or protocol. This definition includes values that are typically thought of as "markup" but can also include other values, such as the name of a field in an HTTP header. Syntactic content consists of all of the characters that form the <em>structure</em> of a format or protocol. For example, <span class="qchar">&lt;</span> and <span class="qchar">&gt;</span> (as well as the element name and various attributes they surround) are part of the syntactic content in an HTML document.</p>
        
        <p>Syntactic content usually is defined by a specification or specifications and includes both the defined, reserved keywords for the given protocol or format as well as string tokens and identifiers that are defined by document authors to form the structure of the document (rather than the "content" of the document).</p>
        
        <p>A <dfn id="def_vocabulary">vocabulary</dfn> is the list of reserved keywords and/or rules for assigning <a>user-supplied values</a> (such as identifiers) in a format or protocol. This can include restrictions on range, order, or type of characters that can appear in different places.</p>
        
        <p>For example, HTML defines the names of its elements and attributes, as well as enumerated attribute values, which defines the "vocabulary" of HTML <a>syntactic content</a>. Another example would be ECMAScript, which restricts the range of characters that can appear at the start or in the body of an identifier or variable name. It applies different rules for other cases, such as to the values of string literals.</p>
		
		<p>Values within a <a>vocabulary</a> fall into two broad classes: those that are meant to be seen, read, or interacted with by humans (and thus might be expected to contain natural language text); and those that are application or protocol internal and not intended for human interaction.</p>
		
		<p>A <dfn>user-facing identifier</dfn> is an identifier defined by or assigned by a user in a <a>vocabulary</a> that is intended to be at least potentially visible to end-users (and thus is <a>localizable content</a>).</p>
		
		<p>An <dfn>application internal identifier</dfn> is an identifier defined by or assigned by a user in a <a>vocabulary</a> that is internal to the document format or protocol and not intended for human interaction. Such values are generally not <a>localizable content</a>.</p>
        
        <p>A <dfn data-lt="user-supplied value|user-supplied values">user-supplied value</dfn> is unreserved <a>syntactic content</a> in a <a>vocabulary</a> that is assigned by users, as distinct from reserved keywords in a given format or protocol. Users generally expect that their user-supplied values can be words or phrases in their preferred <a>natural language</a>. This is why [[CHARMOD]] recommends that "Specifications SHOULD NOT arbitrarily exclude code points from the full range of Unicode code points from <code>U+0000</code> to <code>U+10FFFF</code> inclusive."</p>
        
        <aside class="example">
		  <p>CSS defines the syntax of a style sheet and reserves a number of keywords, such as <code>margin-left</code> or <code>font-family</code>, or values such as <code>10px</code>. All of these definitions are part of the <a>syntactic content</a> of a CSS style sheet. CSS also allows users to define certain values such as class names using a wide range of Unicode characters. These <a>user-supplied values</a> are also part of the <a>syntactic content</a> of the style sheet where they appear.</p>
        </aside>
        
        <aside class="example">
          <p><cite>XML</cite> [[XML10]] defines specific elements, attributes, and values that are reserved across all XML documents. Thus, the word <code class="kw" translate="no">encoding</code> has a defined meaning inside the XML document declaration: it is a reserved name. XML also allows a user to define elements and attributes for a given document, for example, by using a DTD. In a document that uses a DTD that defines an element called <code class="kw">&lt;muffin&gt;</code>, <span class="qterm">muffin</span> is a part of the syntactic content.</p>
        </aside>
        
        <p><dfn>Localizable content</dfn> refers to document contents intended as human-readable text and <b>not</b> to any of the surrounding or embedded syntactic content that form part of the document structure. Note that syntactic content can have localizable content embedded in it, such as when an [[HTML]] <code class="kw">img</code> element has an <code class="kw">alt</code> attribute containing a description of the image.</p>
        
        <aside class="example">
	       <p>Here is an example (similar to the one found in [[STRING-META]]) of a JSON document containing a mixture of syntactic and localizable content. The values whose key is <code>value</code> (in the fields <code>title</code>, <code>author</code>, and <code>publisher</code>) are localizable content. Notice that they are associated with language and base direction metadata.</p>
	       <p>The keys (<code>isbn</code>, <code>bookLanguage</code>, <code>title</code> etc.) are application internal identifiers in this document's vocabulary. Values such as the publication date (<code>2008-01-01</code>) are user-supplied values.</p>
<!--
 Title below is "HTML and CSS: Design and Build Websites"
 ASIN: 1118871642
 ISBN-13: 978-1118871645
 ISBN-10: 1118871642
-->
<p id="example1Data" style="white-space:pre;font-family:monospace">
{
    // syntactic content and user-values
    "isbn":             "978-111887164-5",
    "bookLanguage":     "ar",
    "pubDate":          "2008-01-01",
    "downloadLocation": "https://example.com/books/978-111887164-5",
    "isTranslated":     true,
    "updateDate":       "2021-04-31T19:23:14Z",
    
    // localizable content
    "title": {
        "value": "<span dir=rtl>HTML &#x0648; CSS: &#x062A;&#x0635;&#x0645;&#x064A;&#x0645; &#x0648; &#x0625;&#x0646;&#x0634;&#x0627;&#x0621; &#x0645;&#x0648;&#x0627;&#x0642;&#x0639; &#x0627;&#x0644;&#x0648;&#x064A;&#x0628;</span>",
        "lang":  "ar-AE",
        "dir":   "rtl"
    },
    "author": {
        "value": "Jon Duckett",
        "lang":  "en",
        "dir":   "ltr"
    },
    "publisher": {
        "value": "&#x0645;&#x0643;&#x062A;&#x0628;&#x0629;",
        "lang":  "ar",
        "dir":   "rtl"
    },
},
</p>

        </aside>
          
        <p>A <dfn data-lt="resource|resources">resource</dfn>, in the context of this document,  is a given document, file, or protocol "message" which includes both the <a>localizable content</a> as well as the <a>syntactic content</a> such as identifiers surrounding or containing it. For example, in an HTML document that also has some CSS and a few <code class="kw" translate="no">script</code> tags with embedded JavaScript, the entire HTML document, considered as a file, is a resource. This term is intentionally similar to the term 'resource' as used in [[RFC3986]], although here the term is applied loosely. </p>
          
	
        <p>A <dfn data-lt="grapheme|graphemes">grapheme</dfn> is a sequence of
          one or more characters in a visual representation of some text
          that a typical user would perceive as being a single unit (<q>character</q>).
          Graphemes are important for a number of text operations such as
          sorting or text selection, so it is necessary to be able to compute
          the boundaries between each user-perceived character. Unicode defines
          the default mechanism for computing graphemes in <cite>Unicode
            Standard Annex #29: Text Segmentation</cite> [[!UAX29]] and calls
          this approximation a <dfn>grapheme cluster</dfn>. There are two types
          of default grapheme cluster defined. Unless otherwise noted, grapheme
          cluster in this document refers to an extended default grapheme
          cluster. (A discussion of grapheme clusters is also given in Section 2
           of the <cite>Unicode Standard</cite>, [[!Unicode]]. Cf. near the end of
           <a href="http://www.unicode.org/versions/latest/ch02.pdf">Section 2.11</a>
           in version 8.0 of The Unicode Standard)</p>
        <p>Because different natural languages have different needs, grapheme clusters
          can also sometimes require tailoring. For example, a Slovak user might
          wish to treat the default pair of grapheme clusters "ch" as a single
          grapheme cluster. Note that the interaction between the language of
          string content and the end-user's preferences might be complex.</p>
        <aside class="example" id=graphemeExample>
			<p>The Hindi word for Unicode <q>&#x92f;&#x942;&#x928;&#x93f;&#x915;&#x94b;&#x921;</q> is composed of seven Unicode characters from the Devanagari script.
			</p>
          <p>Most users would identify this word as containing four units of text. Each of the first three graphemes consists of two characters: a syllable and a modifying vowel character. So the word contains seven Unicode characters, but only four graphemes:</p>
            
            <table style="width: 70%; margin-left: 15%; margin-right: 15%">
				<tr>
					<td style="width: 30%">Word</td>
					<td colspan=7 class="bigtext">&#x92f;&#x942;&#x928;&#x93f;&#x915;&#x94b;&#x921;</td>
				</tr>
				<tr>
					<td>Graphemes</td>
					<td class="bigtext" colspan=2>&#x92f;&#x942;</td>
					<td class="bigtext" colspan=2>&#x928;&#x93f;</td>
					<td class="bigtext" colspan=2>&#x915;&#x94b;</td>
					<td class="bigtext">&#x921;</td>
				</tr>
				<tr>
					<td>Code Points</td>
					<td class="bigtext">&#x92f;</td>
					<td class="bigtext">&#x942;</td>
					<td class="bigtext">&#x928;</td>
					<td class="bigtext">&#x93f;</td>
					<td class="bigtext">&#x915;</td>
					<td class="bigtext">&#x94b;</td>
					<td class="bigtext">&#x921;</td>
				</tr>
				<tr>
					<td></td>
					<td style="text-align:center">U+092F</td>
					<td style="text-align:center">U+0942</td>
					<td style="text-align:center">U+0928</td>
					<td style="text-align:center">U+093F</td>
					<td style="text-align:center">U+0915</td>
					<td style="text-align:center">U+094B</td>
					<td style="text-align:center">U+0921</td>
				</tr>
            </table>
        </aside>
        <section>
        <h5>Terminology Examples</h5>
        <p>This section illustrates some of the terminology defined above. For illustration purposes we'll use the following small HTML file as an example (line numbers added for reference):</p>
          <div class=terminologyExample>
            <p class=syntaxExample><span class=lnum>1 </span> <span class="markup">&lt;<span class="vocabulary">html</span> <span class="vocabulary">lang</span>="<span class=userValue>en</span>" <span class="vocabulary">dir</span>="<span class="vocabulary">ltr</span>"&gt;</span></p>
            <p class=syntaxExample><span class=lnum>2 </span><span class="markup">&lt;<span class="vocabulary">head</span>&gt;</span></p>
            <p class=syntaxExample><span class=lnum>3 </span><span class="markup">&nbsp;&nbsp;&lt;<span class="vocabulary">meta</span> <span class="vocabulary">charset</span>="<span class=userValue>UTF-8</span>"&gt;</span></p>
            <p class=syntaxExample><span class=lnum>4 </span><span class=markup>&nbsp;&nbsp;&lt;<span class="vocabulary">title</span>&gt;</span><span class="shakespeare">Shakespeare</span><span class="markup">&lt;/<span class="vocabulary">title</span>&gt;</span></p>
            <p class=syntaxExample><span class=lnum>5 </span>&lt;/<span class="vocabulary">head</span>&gt;</p>
            <p class=syntaxExample><span class=lnum>6 </span>&lt;<span class="vocabulary">body</span>&gt;</p>
            <p class=syntaxExample><span class=lnum>7 </span><span class=markup>&nbsp;&nbsp;&lt;<span class="vocabulary">img</span> <span class="vocabulary">src</span>="<span class="userValue">shakespeare.jpg</span>" <span class="vocabulary">alt</span>="<span class="userValue"><span class="shakespeare">William Shakespeare</span></span>" <span class="vocabulary">id</span>="<span class="userValue">shakespeare_image</span>"&gt;</span></p>
            <p class=syntaxExample><span class=lnum>8 </span><span class=markup>&nbsp;&nbsp;&lt;<span class="vocabulary">p</span>&gt;</span><span class="shakespeare">What<span class="markup">&amp;#x2019;</span>s in a name? That which we call a rose by any other name would smell as sweet.</span><span class="markup">&lt;/<span class="vocabulary">p</span>&gt;</span></p>
            <p class=syntaxExample><span class=lnum>9 </span>&lt;/<span class="vocabulary">body</span>&gt;</p>
            <p class=syntaxExample><span class=lnum>10 </span><span class=markup>&lt;/<span class="vocabulary">html</span>&gt;</span> </p>
          </div>
          <ul style="text-align:left">
          <li>Everything inside the black rectangle (that is, in this HTML file) is part of the <a>resource</a>.</li>
          <li><a>Syntactic content</a> in this case includes all of the HTML markup. There are only two strings that are <strong>not</strong> part of the syntactic content: the word <em>"Shakespeare"</em> on line 4 and the sentence <em>"What&#x2019;s in a name? That which we call a rose by any other name would smell as sweet."</em> on line 8. (The HTML entity <q><kbd>&amp;#x2019;</kbd></q> embedded in the sentence on line 8 <em>is</em> part of the syntactic content.)</li>
          <li><a>Localizable content</a> is shown in a <span class="shakespeare">bold blue font with a gray background</span>. In addition to the non-syntactic content, the <kbd>alt</kbd> value on line 7 (<em><q>William Shakespeare</q></em>) is localizable content.</li>
          <li>User-supplied values are shown in <span class="userValue">italics</span>. In this case there are three user-supplied values on line 7: the values of the <kbd>src</kbd>, <kbd>alt</kbd>, and <kbd>id</kbd> attributes of the <kbd>img</kbd> tag. In addition, the value of the <kbd>lang</kbd> attribute on line 1 and the <kbd>charset</kbd> attribute on line 3 are user-supplied values.</li>
          <li><a>Vocabulary</a> is shown with <span class="vocabulary">red underlining</span>. The vocabulary of an HTML document are the elements and attributes (as well as some of the attribute values, such as the value <kbd>ltr</kbd> for the attribute <kbd>dir</kbd> in the example above) defined in [[HTML]].</li>
          </ul>
          <p class=note>All of the text above (all text in a text file) makes up the resource. It's possible that a given resource will contain no <a>localizable content</a> at all (consider an HTML document consisting of four empty <code>div</code> elements styled to be orange rectangles). It's also possible that a resource will contain <em>no</em> syntactic content and consist solely of <a>localizable content</a>: for example, a plain text file with a soliloquy from <cite>Hamlet</cite> in it. Notice too that the HTML entity <code>&amp;#x2019;</code>appears in the localizable content and belongs to both the localizable content and the syntactic content in this resource.</p>
        </section>
      </section>
      
      <section id="conformance">
        <p>This document describes best practices for the authors of other specifications, as well as recommendations for implementations and content authors. These best practices can also be found in the Internationalization Working Group's document <cite>Internationalization Best Practices for Spec Developers</cite> [[!INTERNATIONAL-SPECS]], which is intended to serve as a general reference for all Internationalization best practices in W3C specifications.</p>
        
        <!--p class="advisement" id="charmod_consistent_format"><a class="self" href="#charmod_consistent_format">[C] </a>When a best practice or recommendation appears in this document, it has been styled like this paragraph. Recommendations for specifications and spec authors are labelled [S]. Recommendations for implementations and software developers are labelled [I]. Recommendations for content and content authors are labelled [C].</p-->
        
        <p>Best practices in this document use [[!RFC2119]] keywords in order to clarify the Internationalization Working Group's intentions regarding a specific recommendation. Following the recommendations in this document can help avoid issues during the W3C's "wide review" process, during implementation, or in the content that authors produce. This document is not, itself, normative and can be revised from time to time.</p>
        
        <p>Specifications can claim conformance to this document if they:</p>
        <ol type="1">
          <li>do not violate any conformance criteria preceded by <span class=qrec>[S]</span> where the imperative is MUST or MUST NOT</li>
          <li>document the reason for any deviation from criteria where the imperative is SHOULD, SHOULD NOT, or RECOMMENDED</li>
          <li>make it a conformance requirement for implementations to conform to this document</li>
          <li>make it a conformance requirement for content to conform to this document</li>
        </ol>

        <p class=note>Requirements placed on specifications might indirectly cause requirements to be placed on implementations or content that claim to conform to those specifications.</p>
        <p>Where this specification contains a procedural description, it is to be understood as a way to specify the desired external behavior. Implementations MAY use other means of achieving the same results, as long as observable behavior is not affected.</p>
      </section>
    </section>
    
    <section id="problemStatement">
      <h2>The String Matching Problem</h2>
      <p>The Web is primarily made up of document formats and protocols based on
        character data. These formats or protocols can be viewed as a set of <a>resources</a> consisting mainly of text files that include some form of structural markup or <a>syntactic content</a>. Processing such syntactic content or document data requires
        string-based operations such as matching (including regular expressions), indexing, searching, sorting,
        and so forth.</p>
      <p>Users, particularly implementers, sometimes have naïve expectations regarding the matching or non-matching
        of similar strings or of the efficacy of different transformations they might apply to text, particularly to
        syntactic content, but including many types of text processing on the Web.</p>
      <p>Because fundamentally the Web is sensitive to the different ways in which text might be represented in a
        document, failing to consider the different ways in which the same text can be represented can confuse 
        users or cause unexpected or frustrating results. In the sections below, this document examines the different
        types of text variation that affect both user perception of text on the Web and the string processing on which
        the Web relies.</p>
      <section id="definitionCaseFolding">
        <h3>Case Mapping and Case Folding</h3>
        <p>Some scripts and writing systems make a distinction between UPPER, lower, and Title case characters. Most scripts, including the Brahmic scripts of India, the Arabic script, and the  scripts used to write Chinese, Japanese, or Korean, do not have a case distinction, but some important ones do. Examples of such scripts include the Latin script used in the majority of this document, as well as scripts such as Greek, Armenian, and Cyrillic. </p>
 		
		<p><dfn>Case mapping</dfn> is the process of transforming characters to a specific case, such as UPPER, lower, or Titlecase. For those scripts that have a case distinction, Unicode defines a <em>default</em> UPPER, lower, and Titlecase character mapping for each Unicode code point. Case mapping, at first, appears simple. However there are variations that need to be considered when treating the full range of Unicode in diverse languages.</p>
		
		        
       <aside class="note">
       <p>For more information, see [[!Unicode]] <a href="https://www.unicode.org/versions/latest/ch05.pdf">Chapter 5</a> in the section titled <em>Case Mappings</em>) for a detailed discussion of case mapping and case folding. </p>
       </aside>  
		
		<aside class="example">
		<p>For example here is a character with mappings to all three case variations. These mappings are defined in the <a href="https://www.unicode.org/Public/UCD/latest/ucd/">Unicode Character Database</a> (UCD).</p>
		<table>
			<tr>
				<th>Uppercase</th>
				<th>Lowercase</th>
				<th>Titlecase</th>
			</tr>
			<tr>
				<td class="exampleChar">&#x1c4;</td>
				<td class="exampleChar">&#x1c6;</td>
				<td class="exampleChar">&#x1c5;</td>
			</tr>
			<tr>
				<td>U+01C4</td>
				<td>U+01C6</td>
				<td>U+01C5</td>
			</tr>
		</table>
		</aside>
		
		          
       <p><dfn>Case folding</dfn> is the process of making two texts which differ only in case identical for comparison purposes, that is, it is meant for the purpose of string matching. This is distinct from <a>case mapping</a>, which is primarily meant for display purposes. As with the default case mappings, Unicode defines default case fold mappings ("case folding") for each Unicode code point. Unicode defines two forms of case folding, which we'll examine below.</p>
       
       <p>Since most scripts do not have a case distinction, as with case mappings, most Unicode code points do not require a case folding. For those code points that 
		have a case folding, the majority have a simple, straight-forward mapping to another single matching (generally lowercase) code point. Unicode 
		calls this set of foldings <code class="kw">common</code>, since both types of case folding defined by Unicode includes these.
         </p>
         
         <aside class="example">
         <p>Here are some examples of <code class="kw">common</code> case foldings:</p>
         <table>
           <tr>
			   <td class="exampleChar">A</td>
			   <td>&#x21d2;</td>
			   <td class="exampleChar">a</td>
			   <td><span class="uname">LATIN CAPITAL LETTER A</span> to <span class="uname">LATIN SMALL LETTER A</span></td>
           </tr>
           <tr>
			   <td class="exampleChar">&#x398;</td>
			   <td>&#x21d2;</td>
			   <td class="exampleChar">&#x3b8;</td>
			   <td><span class="uname">GREEK CAPITAL LETTER THETA</span> to <span class="uname">GREEK SMALL LETTER THETA</span></td>
           </tr>
           <tr>
			   <td class="exampleChar">&#x414;</td>
			   <td>&#x21d2;</td>
			   <td class="exampleChar">&#x434;</td>
			   <td><span class="uname">CYRILLIC CAPITAL LETTER DE</span> to <span class="uname">CYRILLIC SMALL LETTER DE</span></td>
           </tr>
         </table>
         </aside>
         
         
		  <p>A few characters have a case folding that map one Unicode code point to two or more code points. This set of case foldings are called the <code class="kw">full</code> case foldings. The <code class=kw>full</code> and <code class=kw>common</code> case foldings are used together to provide the default case folding for all of Unicode. We refer to this form of case folding as <dfn>full casefolding</dfn> or <dfn>Unicode full</dfn> in this document.
         </p>
         
         <aside class="example">
          <p>One well-known example of a <code class="kw">full</code> case fold mapping is the character <span class="qchar">&#xdf;</span>
		  <span class="uname" translate="no">U+00DF LATIN SMALL LETTER SHARP S</span>, a letter that is commonly used in the German language. The <code class="kw">full</code> case folding and the lower case mapping of this character is to two ASCII letters 's'. The upper case mapping is to "SS".
		  </p>
         <table>
           <tr>
			   <td class="exampleChar">&#xdf;</td>
			   <td>&#x21d2;</td>
			   <td class="exampleChar">ss</td>
			   <td><span class="uname">LATIN SMALL LETTER SHARP S</span> to <span class="uname">LATIN SMALL LETTER S</span> + <span class="uname">LATIN SMALL LETTER S</span></td>
           </tr>
		 </table>
         </aside>
         
		  <p>Because some applications cannot allocate additional storage when performing a case fold operation, Unicode provides a <code class="kw">simple</code> case folding that maps a code point that would normally fold to more or fewer code points to use a single code point for comparison purposes instead. Unlike the full folding, this folding invariably alters the content (and potentially the meaning) of the text. As with <a>full casefolding</a>, the <dfn>simple casefolding</dfn> or <dfn>Unicode simple</dfn> casefold, is a combination of <code class=kw>simple</code> and <code class=kw>common</code> mappings so as to cover the full range of Unicode. <a>Unicode simple</a> is not appropriate for use on the Web. </p>
		  
		  <aside class="example">

		  <p>Examples of <code class=kw>full</code> versus <code class=kw>simple</code> case fold variations can be found in the Greek script, where several precomposed characters have multi-character case foldings. The table below shows one such example, the character <span class="codepoint" translate="no"><span lang="el">&#x1F9B;</span> [<span class="uname">U+1F9B GREEK CAPITAL LETTER ETA WITH DASIA AND VARIA AND PROSGEGRAMMENI</span>]</span> and its <code class="kw">full</code> and <code class="kw">simple</code> case foldings:</p>
					
		  <table style="width: 100%">
     
		     <tr>
			    <td class="exampleChar">&#x1f9b;</td>
			    <td>&#x21d2;</td>
		        <td class="exampleChar">&#x1f23;&#x03b9;</td>
		        <td><code class=kw>full</code> case fold: <span class="codepoint" translate="no"><span class="uname">U+1F23 GREEK SMALL LETTER ETA WITH DASIA AND VARIA</span> + <span class="uname">U+03B9 GREEK SMALL LETTER IOTA</span></span></td>
		     </tr>
		     <tr>
				<td class="exampleChar">&#x1f9b;</td>
			    <td>&#x21d2;</td>
		        <td class="exampleChar">&#x1f93;</td>
		        <td><code class=kw>simple</code> case fold: <span class="codepoint" translate="no"><span class="uname">U+1F93 GREEK SMALL LETTER ETA WITH DASIA AND VARIA AND YPOGEGRAMMENI</span></span></td>
		     </tr>
		  </table>

		  </aside>
          
        <p>Note that case folding removes information from a string which cannot be recovered later. For example, two <span class="qchar">s</span> letters in German do not necessarily represent  <span class="qchar">&#xdf;</span> in unfolded text.</p>
		
		<section id="caseMappingLanguageSensitivity">
	    <h3>Language Sensitivity</h3>
	    
        <p>Another aspect of case mapping and case folding is that it can be language sensitive.
          Unicode defines <em>default</em> case mappings and case foldings for each encoded character, but
          these are only defaults and are not appropriate in all cases. Some
          languages need case mapping to be tailored to meet specific linguistic
          needs. One example of this are Turkic languages written in the
          Latin script:</p>
          
        <aside class="example">
		  <table>
			  <tr>
				  <th colspan=4>Default Folding</th>
			  </tr>
			  <tr>
		     <td class="exampleChar">I</td>
		     <td>&#x21d2;</td>
		     <td class="exampleChar">i</td>
		     <td>Default folding of letter I</td>
		     </tr>
		     <tr>
				  <th colspan=4>Turkic Language Folding</th>
             </tr>
           <tr>
			 <td class="exampleChar">I</td>
		     <td>&#x21d2;</td>
		     <td class="exampleChar">&#x131;</td>
		     <td>Turkic language folding of dotless (ASCII) letter I</td>
		   </tr>
		   <tr>
			 <td class="exampleChar">&#x130;</td>
		     <td>&#x21d2;</td>
		     <td class="exampleChar">i</td>
		     <td>Turkic language folding of dotted letter I</td>
		   </tr>
		  </table>
		  </aside>
			
          <p>While the example above (and this document in general) focuses on case folding for the purpose of matching, note that case mapping is also language-specific. The name of the second largest city in Turkey is "<code>Diyarbakır</code>", which
           contains both the dotted and dotless letters <span class="qchar">i</span>. 
            </p>
            
        <aside class="example">
            <p><span class="exampleChar">Diyarbakır</span> &#x21d2; <code>text-transform: uppercase</code> &#x21d2; <span class="exampleChar">DİYARBAKIR</span></p>
            <p>Notice that the ASCII letter <span class="codepoint"><span lang="tr">&#x0069;</span> [<span class="uname">U+0069 LATIN SMALL LETTER I</span>]</span> maps to <span class="codepoint"><span lang="tr">&#x0130;</span> [<span class="uname">U+0130 LATIN CAPITAL LETTER I WITH DOT ABOVE</span>]</span>, while the letter <span class="codepoint"><span lang="tr">&#x0131;</span> [<span class="uname">U+0131 LATIN SMALL LETTER DOTLESS I</span>]</span> maps to the ASCII uppercase <span class="codepoint"><span lang="tr">&#x0049;</span> [<span class="uname">U+0049 LATIN CAPITAL LETTER I</span>]</span>. Failure to apply this localized case mapping would change the meaning of the text in Turkish, even though this is the expected mapping in other languages, such as English or German.</p>
            <p>This language-specific tailoring can also be applied to case folding. For example, if the uppercase text needed to be matched against some set of strings in a case-insensitive way:</p>
            <p><span class="exampleChar">D&#x130;YARBAKIR</span> &#x21d2; <code>case fold</code> &#x21d2; <span class="exampleChar">diyarbak&#x131;r</span></p>
        </aside>

        
        </section>
        
        <section id="caseFoldApplication">
	    <h3>Uses for Case Folding</h3>
	    
          <p>Some document formats or protocols seek to aid interoperability or provide an aid to content authors by ignoring case variations in the <a data-lt="vocabulary">vocabulary</a> they define or in <a>user-supplied values</a> permitted by the format or protocol.</p>
          
          <aside class="example">
			  
		<p>One example where this occurs is when matching element names between an HTML document and its associated style sheet. Consider this HTML fragment: </p>
<pre>&lt;style type="text/css"&gt;

  SPAN.hello {
     text-decoration: underline;
  }
&lt;/style&gt;

&lt;span class="hello"&gt;Hello World!&lt;/span&gt;
</pre>

        <p>The <code class="kw" translate="no">SPAN</code> in the stylesheet
          matches the <code class="kw" translate="no">span</code> element in the 
		document, even though the stylesheet uses uppercase and the HTML markup 
		does not.</p>
</aside>
        
        
        <p>Sometimes case can vary in a way that is not semantically meaningful
          or is not fully under the user's control. This is particularly true
          when searching a document, but may sometimes also apply
          when defining rules for matching user- or content-generated values,
          such as identifiers. In these situations, case-<em>in</em>sensitive
          matching might be desirable instead.</p>
          
        <p>When defining a <a>vocabulary</a>, one important consideration is whether the values are restricted to the ASCII [[ASCII]] subset of Unicode or if the vocabulary permits the use of characters (such as accents on Latin letters or a broad range of Unicode including non-Latin scripts) that potentially have more complex case folding requirements. To address these different requirements, there are four types of casefold matching defined by this document for the purposes of string identity matching in document formats or protocols:</p>
        
        <p id="case-sensitive"><dfn data-lt="case-sensitive">Case sensitive matching</dfn>: code points are compared directly with no case folding.</p>
        
        <p id="aci"><dfn data-lt="ASCII case-insensitive|ASCII case-insensitive matching">ASCII case-insensitive matching</dfn> is <a href="https://infra.spec.whatwg.org/#ascii-case-insensitive">defined</a> in [[INFRA]]. This definition compares two sequences of code points as if all ASCII code points in the range 0x41 to 0x5A (A to Z) were mapped to the corresponding code points in the range 0x61 to 0x7A (a to z). ASCII case-insensitive matching can be required when a <a>vocabulary</a> is itself constrained to ASCII.</p>
        
        <p id="uci"><dfn data-lt="Unicode case-insensitive|Unicode case-insensitive matching">Unicode case-insensitive matching</dfn> compares two sequences of code points as if the <a>Unicode full</a> casefolding (see above) had been applied to both input sequences.</p>
        
        <p><dfn>Language-sensitive case-sensitive matching</dfn> is useful in the rare case where a document format or protocol contains information about the language of the syntactic content and where language-sensitive case folding might sensibly be applied. These case foldings are defined in the <cite>Common Locale Data Repository</cite> [[UAX35]] project of the Unicode Consortium.</p>
            
        <p>For advice on how to handle case folding see <a href="#handlingCaseFolding"></a>.</p>
   </section>
      </section>
      <section id="unicodeNormalization">
        <h3>Unicode Normalization</h3>
        
        <p>A different kind of variation can occur in Unicode text: sometimes several different <a>Unicode code point</a> sequences can be used to represent the same abstract character. When searching or matching text by comparing code points, these variations in encoding cause text values not to match that users expect to be the same. </p>

      <aside class=example id=aringExample title="Encoding Variations">
		  <p>Consider the character <span class="codepoint"><span lang="en">&#x01FA;</span> [<span class="uname">U+01FA LATIN CAPITAL LETTER A WITH RING ABOVE AND ACUTE</span>]</span>. One way to encode this character is as <span class="uname" translate="no"> U+01FA LATIN CAPITAL LETTER A WITH RING ABOVE AND ACUTE</span>. Here are some of the different character sequences that a document could use to represent this character:</p>
          <table>
			  <tr>
                 <td class=exampleChar style="width:10%">&#x01FA;</td>
                 <td><span class="uname" translate="no">U+01FA</span>—A "precomposed" character.</td>
              </tr>
			  <tr>
                 <td class=exampleChar>A&#x030A;&#x0301;</td>
                 <td><span class="uname" translate="no">A&nbsp;+&nbsp;U+030A&nbsp;+&nbsp;U+0301</span>— A <span class="qterm">base</span> letter <span class="qchar">A</span> followed by two combining marks (<span class="uname" translate="no">U+030A COMBINING RING ABOVE</span> and <span class="uname" translate="no">U+0301 COMBINING ACUTE ACCENT</span>)</td>
              </tr><tr>
				  <td class=exampleChar>&#x00C5;&#x0301;</td>
				  <td><span class="uname" translate="no">U+00C5 + U+0301</span>—An accented letter (<span class="uname" translate="no">U+00C5 LATIN CAPITAL LETTER A WITH RING ABOVE</span>) followed by a combining accent (<span class="uname" translate="no">U+0301 COMBINING ACUTE ACCENT</span>)</td>
		      </tr><tr>
		          <td class=exampleChar>&#x212B;&#x0301;</td>
		          <td><span class="uname" translate="no">U+212B + U+0301</span>—A compatibility character (<span class="uname" translate="no">U+212B ANGSTROM SIGN</span>) followed by a combining accent (<span class="uname" translate="no">U+0301 COMBINING ACUTE ACCENT</span>)</td>
		      </tr><tr>
		          <td class=exampleChar>&#xFF21;&#x030A;&#x0301;</td>
		          <td><span class="uname" translate="no">U+FF21 + U+030A + U+0301</span>— A compatibility character <span class="uname" translate="no">U+FF21 FULLWIDTH LATIN LETTER CAPITAL A</span>) followed by two combining marks (<span class="uname" translate="no">U+030A COMBINING RING ABOVE</span> and <span class="uname" translate="no">U+0301 COMBINING ACUTE ACCENT</span>)</td>
		      </tr>
          </table>

         <p>Each of the above strings contains the same apparent <span class="quote">meaning</span> as <span class="codepoint"><span lang="en">&#x01FA;</span> [<span class="uname">U+01FA LATIN CAPITAL LETTER A WITH RING ABOVE AND ACUTE</span>]</span>, but each one is encoded slightly differently. More variations are possible, but are omitted for brevity.</p>
        
        </aside>
        
        <p>Because applications need to find the semantic equivalence in texts
          that use different code point sequences, Unicode defines a means of
          making two semantically equivalent texts identical: the Unicode
          Normalization Forms [[!UAX15]].</p>
		  <aside class="addition">
		  <div class="note-title marker"><span>Note Well</span></div>
		  <p>Unicode Normalization does not guarantee that two 
		  identical-appearing strings that are in a given Unicode Normalization Form use the same sequence of code points.
		  See <a href="#normalizationLimitations"></a> for more information.</p>
		</aside>
        <p><a>Resources</a> are often susceptible to the effects of these variations because their specifications and implementations on the Web do not require Unicode Normalization of the text, nor do they take into consideration the string matching algorithms used when processing the <a>syntactic content</a> (including <a>user-supplied values</a>) and <a>localizable content</a> later. For this reason, content developers need to ensure that they have provided a consistent representation in order to avoid problems later.</p>
        
        <p>However, it can be difficult for users to assure that a given <a>resource</a>
          or set of resources uses a consistent textual representation because
          the differences are usually not visible when viewed as text. Tools and
          implementations thus need to consider the difficulties experienced by
          users when visually or logically equivalent strings that "ought to"
          match (in the user's mind) are considered to be distinct values.
          Providing a means for users to see these differences and/or normalize
          them as appropriate makes it possible for end users to avoid failures
          that spring from invisible differences in their source documents. For
          example, the W3C Validator warns when an HTML document is not fully in
          Unicode Normalization Form C.</p>
        <section id="canonical_compatibility">
          <h4>Canonical vs. Compatibility Equivalence</h4>
          <p>Unicode defines two types of equivalence between characters: <em>canonical equivalence</em> and <em>compatibility equivalence</em>.</p>
          <p><dfn>Canonical equivalence</dfn> is a fundamental equivalency between Unicode code points or sequences of Unicode code points that represent the same abstract character. Canonically equivalent sequences ideally should have the same visual appearance (although there are many factors that can cause them to appear somewhat differently) and they should be treated and processed as if they were identical. Unicode defines a process called <em>canonical decomposition</em> that removes these primary distinctions between two differently-encoded but canonically equivalent texts.</p>
          <p>Examples of canonical equivalence defined by Unicode include:</p>
          <ul class="dropExampleList">
            <li class="dropExampleItem"><span class="dropExample">Ç<span style="font-size:75%">
                  vs.</span>C&#x0327;</span> <em>Precomposed versus combining
                sequences.</em> Some characters can be composed from a base
              character followed by one or more combining characters. The same
              characters are sometimes also encoded as a distinct "precomposed"
              character. In this example, the character <span class="codepoint"><span lang="en">&#x00C7;</span> [<span class="uname">U+00C7 LATIN CAPITAL LETTER C WITH CEDILLA</span>]</span> is canonically equivalent to the character sequence starting with the base character <span class="codepoint"><span lang="en">&#x0043;</span> [<span class="uname">U+0043 LATIN CAPITAL LETTER C</span>]</span> followed by <span class="codepoint"><span lang="en">&#x25CC;&#x0327;</span> [<span class="uname">U+0327 COMBINING CEDILLA​</span>]</span>. Such equivalence can extend to characters with multiple combining marks.</li>
            <li class="dropExampleItem"><span class="dropExample">q&#x0307;&#x0323;<span style="font-size:75%">
                  vs.</span>q&#x0323;&#x0307;</span> <em>Order of combining marks.</em> When a base character is modified by multiple combining marks, the order of the combining marks might not represent a distinct character. Here the sequence <span class="codepoint"><span lang="en">&#x0071;</span> [<span class="uname">U+0071 LATIN SMALL LETTER Q</span>]</span> <span class="codepoint"><span lang="en">&nbsp;&#x0307;</span> [<span class="uname">U+0307 COMBINING DOT ABOVE​</span>]</span> <span class="codepoint"><span lang="en">&nbsp;&#x0323;</span> [<span class="uname">U+0323 COMBINING DOT BELOW​</span>]</span> and <span class="codepoint"><span lang="en">&#x0071;</span> [<span class="uname">U+0071 LATIN SMALL LETTER Q</span>]</span> <span class="codepoint"><span lang="en">&nbsp;&#x0323;</span> [<span class="uname">U+0323 COMBINING DOT BELOW​</span>]</span> <span class="codepoint"><span lang="en">&nbsp;&#x0307;</span> [<span class="uname">U+0307 COMBINING DOT ABOVE​</span>]</span> are equivalent, even though the combining marks are in a different order. Note that this example is chosen carefully: the dot-above character and dot-below character are on opposite "sides" of the base character. The order of combining diacritics on the same side often has a positional meaning (although there are cases where the order doesn't matter to the presentation).</li>
            <li class="dropExampleItem"><span class="dropExample">&#x2126;<span style="font-size:75%">
                  vs.</span>&#x03a9;</span> <em>Singleton mappings.</em> These result from the need to separately encode otherwise equivalent characters to support legacy character encodings. In this example, the Ohm symbol <span class="codepoint"><span lang="en">&#x2126;</span> [<span class="uname">U+2126 OHM SYMBOL</span>]</span> is canonically equivalent (and identical in appearance) to the Greek letter Omega <span class="codepoint"><span lang="el">&#x03A9;</span> [<span class="uname">U+03A9 GREEK CAPITAL LETTER OMEGA</span>]</span>. (Another example of a singleton is <span class="codepoint"><span lang="en">&#x212B;</span> [<span class="uname">U+212B ANGSTROM SIGN</span>]</span> in the <a href="#aringExample">encoding variations example</a> above)</li>
            <li class="dropExampleItem"><span class="dropExample">&#xac00;<span style="font-size:75%">
                  vs.</span>&#x1100;&#x1161;</span> <em>Hangul.</em> The Hangul script is
              used to write the Korean language. This script is constructed
              logically, with each syllable being a roughly-square <a>grapheme</a>
              formed from specific sub-parts that represent consonants and
              vowels. These specific sub-parts, called <em>jamo</em>, are
              encoded in Unicode. So too are the precomposed syllables. Thus the
              syllable <span class="codepoint"><span lang="ko">&#xAC00;</span> [<span class="uname">U+AC00 [Hangul Syllable, First]</span>]</span> is canonically equivalent to its constituent <em>jamo</em> characters <span class="codepoint" translate="no"><span lang="ko">&#x1100;&#x1161;</span> [<span class="uname">U+1100 HANGUL CHOSEONG KIYEOK</span> + <span class="uname">U+1161 HANGUL JUNGSEONG A</span>]</span>.</li>
          </ul>
          <p><dfn>Compatibility equivalence</dfn> is a weaker equivalence
            between Unicode characters or sequences of Unicode characters that represent the
            same abstract character, but may have a different visual appearance
            or behavior. Generally the process called <em>compatibility decomposition</em> removes
            formatting variations, such as superscript, subscript, rotated,
            circled, and so forth, but other variations also occur. In many
            cases, characters with compatibility decompositions represent a
            distinction of a semantic nature; replacing the use of distinct
            characters with their compatibility decomposition can therefore
            change the meaning of the text. Texts that are equivalent after 
		  compatibility decomposition often were not perceived as being 
		  identical beforehand and SHOULD NOT be treated as equivalent by a formal
            language.</p>
            
          <aside class=example>
          <p>The following table illustrates various kinds of compatibility equivalence in Unicode:</p>
              <table class=data>
                <thead>
                  <tr>
                    <th>Compatibility Equivalance</th>
                    <th style="text-align:center">Original Character</th>
                    <th></th>
                    <th style="text-align:center; width:30%">Compatibility Mapping</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td rowspan=2><strong>Font variants</strong>—characters that have a specific visual appearance (generally associated with a specialized use, such as in mathematics).</td>
                    <td style="text-align: center"><span class="exampleChar">&#x210c;</span><br><span class=uname>U+201C</span></td>
                    <td style="text-align: center" rowspan=2>&#x21d2;</td>
                    <td style="text-align: center" rowspan=2><span class="exampleChar">H</span><br><span class=uname>U+0048</span></td>
                   </tr>
                   <tr>
                    <td style="text-align: center"><span class="exampleChar">&#x210d;</span><br><span class=uname>U+210D</span></td>
                  </tr>
                  <tr>
                    <td><strong>Breaking versus non-breaking</strong>—variations in breaking or joining rules, such as the difference between a <span class="qterm">normal</span> and a non-breaking space.</td>
                    <td style="text-align: center"><span class="uname" translate="no">NON-BREAKING SPACE</span><br><span class=uname>U+00A0</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="uname" translate="no">SPACE<br>U+0020</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Presentation forms of Arabic</strong>— characters that encode the specific shapes (isolated, final, initial, and medial) needed by visual legacy encodings of the Arabic script.</td>
                    <td style="text-align: center"><span class="exampleChar">&#xfee9;</span><br><span class=uname>U+FEE9</span></td>
                    <td style="text-align: center" rowspan=4>&#x21d2;</td>
                    <td style="text-align: center" rowspan=4><span class="exampleChar">&#x647;</span><br><span class=uname>U+0647</span></td>                   
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xfeea;</span><br><span class=uname>U+FEEA</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xfeeb;</span><br><span class=uname>U+FEEB</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xfeec;</span><br><span class=uname>U+FEEC</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Circled</strong>—numbers, letters, and other characters in a circled, bullet, or other presentational form; often used for lists, footnotes, and specialized presentation</td>
                    <td style="text-align: center"><span class="exampleChar">&#x2460;</span><br><span class=uname>U+2460</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">1</span><br><span class=uname>U+0031</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x2469;</span><br><span class=uname>U+2469</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">10</span><br><span class=uname>U+0031 U+0030</span></td>
                  </tr><tr>
					<td style="text-align: center"><span class="exampleChar">&#x24b6;</span><br><span class=uname>U+24B6</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">A</span><br><span class=uname>U+0041</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x329e;</span><br><span class=uname>U+329E</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">&#x5370;</span><br><span class=uname>U+5370</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Width variation, size, rotated presentation forms</strong>—narrow vs. wide presentational forms of characters (such as those associated with legacy multibyte encodings), as well as "rotated" presentation forms necessary for vertical text.</td>
                    <td style="text-align: center"><span class="exampleChar">&#xff76;</span><br><span class=uname>U+FF76</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">&#x30ab;</span><br><span class=uname>U+30AB</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xfe37;</span><br><span class=uname>U+FE37</span></td>
                    <td style="text-align: center" rowspan=2>&#x21d2;</td>
                    <td style="text-align: center" rowspan=2><span class="exampleChar">{</span><br><span class=uname>U+007B</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xff5b;</span><br><span class=uname>U+FF5B</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xff21;</span><br><span class=uname>U+FF21</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">A</span><br><span class=uname>U+0041</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Superscripts/subscripts</strong>—superscript or subscript letters, numbers, and symbols.</td>
                    <td style="text-align: center"><span class="exampleChar">&#x2079;</span><br><span class=uname>U+2079</span></td>
                    <td style="text-align: center" rowspan=2>&#x21d2;</td>
                    <td style="text-align: center" rowspan=2><span class="exampleChar">9</span><br><span class=uname>U+0039</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x2089;</span><br><span class=uname>U+2089</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x00aa;</span><br><span class=uname>U+00AA</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">a</span><br><span class=uname>U+0061</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x208a;</span><br><span class=uname>U+208A</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">+</span><br><span class=uname>U+002B</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong><span class="quote">Squared</span> characters</strong>—East Asian (particularly kana) sequences encoded as a presentation form to fit in a single ideographic "cell" in text.</td>
                    <td style="text-align: center"><span class="exampleChar">&#x3300;</span><br><span class=uname>U+3300</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">&#x30A2;&#x30D1;&#x30FC;&#x30C8;</span><br><span class=uname>U+30A2 U+30D1 U+30FC U+30C8</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x3350;</span><br><span class=uname>U+3350</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">&#x30E6;&#x30A2;&#x30F3;</span><br><span class=uname>U+30E6 U+30A2 U+30F3</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x3250;</span><br><span class=uname>U+3250</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">PTE</span><br><span class=uname>U+0050 U+0054 U+0045</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x3389;</span><br><span class=uname>U+3389</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">kcal</span><br><span class=uname>U+006B U+0063 U+0061 U+006C</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Fractions</strong>—precomposed vulgar fractions, often encoded for compatibility with font glyph sets.</td>
                    <td style="text-align: center"><span class="exampleChar">&#xbc;</span><br><span class=uname>U+00BC</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">1&#x2044;4</span><br><span class=uname>U+0031 U+2044 U+0034</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#xbd;</span><br><span class=uname>U+00BD</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">1&#x2044;2</span><br><span class=uname>U+0031 U+2044 U+0032</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x215f;</span><br><span class=uname>U+215F</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">1&#x2044;</span><br><span class=uname>U+0031 U+2044</span></td>
                  </tr><tr>
                    <td style="text-align: center"><span class="exampleChar">&#x2189;</span><br><span class=uname>U+2189</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">0&#x2044;3</span><br><span class=uname>U+0030 U+2044 U+0033</span></td>
                  </tr>
                  <tr>
                    <td rowspan=4><strong>Others</strong>—compatibility characters encoded for other reasons, generally for compatibility with legacy character encodings. Many of these characters are simply a sequence of characters encoded as a single presentational unit.</td>
                    <td style="text-align: center"> <span class="exampleChar">&#x1c6;</span><br><span class=uname>U+01C6</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">d&#x17e;</span><br><span class=uname>U+0064 U+017E</span></td>
                  </tr><tr>
                    <td style="text-align: center"> <span class="exampleChar">&#x2474;</span><br><span class=uname>U+2474</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">(1)</span><br><span class=uname>U+0028 U+0031 U+0029</span></td>
                  </tr><tr>
                    <td style="text-align: center"> <span class="exampleChar">&#x2488;</span><br><span class=uname>U+2488</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">1.</span><br><span class=uname>U+0031 U+002E</span></td>
                  </tr><tr>
                    <td style="text-align: center"> <span class="exampleChar">&#x2ef3;</span><br><span class=uname>U+2EF3</span></td>
                    <td style="text-align: center">&#x21d2;</td>
                    <td style="text-align: center"><span class="exampleChar">&#x9f9f;</span><br><span class=uname>U+9F9F</span></td>
                  </tr>
                </tbody>
              </table>
          </aside>
          <p>In the above table, it is important to note that the characters
            illustrated are <em>actual Unicode codepoints</em>, not just presentational
            variations due to context or style. Each character was
            encoded into Unicode for compatibility with various legacy character
            encodings. They should not be confused with the normal kinds of
            presentational processing used on their non-compatibility
            counterparts.</p>
          <p>For example, most Arabic-script text uses the characters in the Arabic script block of Unicode (starting at <span class="uname" translate="no">U+0600</span>). The actual glyphs used to display the text are selected using fonts and text processing logic based on the position inside a word (initial, medial, final, or isolated), in a process called "shaping". In the table above, the four presentation forms of the Arabic letter <span class="codepoint"><span lang="ar" dir="rtl">&#x0647;</span> [<span class="uname">U+0647 ARABIC LETTER HEH</span>]</span> are shown. The characters shown are compatibility characters in the <span class="uname" translate="no">U+FE00</span> block, each of which represents a specific "positional" shape and each of the four code points shown have a compatibility decomposition to the <span class="quote">regular</span> Arabic letter <span class="codepoint"><span lang="ar" dir=rtl>&#x0647;</span> [<span class="uname">U+0647 ARABIC LETTER HEH</span>]</span>. These presentation forms are intended only for the support of round-trip encoding conversions with the <a>legacy character encodings</a> that include equivalent presentation forms. Otherwise a string containing a sequence of letters 'heh' is just encoded as a series of <span class=uname translate=no>U+0647</span> code points, with the rendering system and font supplying the appropriate shapes.
          <aside class=example id=bidiCompatibilityExample>
			  <p>Example of a sequence of <span class=uname translate=no>U+0647 ARABIC LETTER HEH</span>. The different letter shapes are provided by the rendering system. Note that Arabic is read from right-to-left, so the "isolated" shape is on the right side of the string (followed by a space), then "initial", "medial", and "final" shapes.</p>
			 <p dir=rtl class=bidiExample>&#x647;&nbsp;&#x647;&#x647;&#x647;</p>
          </aside>
          <p>Similarly, the variations in half-width and full-width forms and rotated
            characters (for use in vertical text) are encoded as separate code
            points, mainly for compatibility with legacy character encodings. In 
		  many cases these variations are associated with the Unicode properties 
		  described in <cite>East Asian Width</cite> [[UAX11]]. See also <cite>Unicode 
		  Vertical Text Layout</cite> [[UTR50]] for a discussion of vertical text 
		  presentation forms.</p>
          <p>In the case of characters with compatibility decompositions, such
            as those shown above, the <span class="qchar">K</span> Unicode
            Normalization forms convert the text to the "normal" or "expected"
            Unicode code point. But the existence of these compatibility
            characters cannot be taken to imply that similar appearance
            variations produced in the normal course of text layout and
            presentation are affected by Unicode Normalization. They are not.</p>
        </section>
        <section id="composition_decomposition">
          <h4>Composition vs. Decomposition</h4>
          <p>These two types of Unicode-defined equivalence are then grouped by another pair of variations: "decomposition" and "composition". In "decomposition", separable logical parts of a visual character are broken out into a sequence of base characters and combining marks and the resulting code points are put into a fixed, canonical order. In "composition", the decomposition is performed and then combining marks are recombined according to certain rules with their base characters.</p>
          <div class="warning">
            <p>Roughly speaking, <abbr title="Normalization Form C">NFC</abbr> is defined such that each combining character sequence (a base character followed by one or more combining characters) is replaced, as far as possible, by a canonically equivalent precomposed character.</p>
            
            <p>It is rather important to notice what this does <strong>not</strong> mean. The resulting character sequence can still contain combining marks, since not all character sequences have a precomposed equivalent. Indeed, as we've seen, many scripts offer no alternative to the use of combining marks, such as the Devanagari vowels in <a href="#graphemeExample">this example</a>. In other cases, a given base character and combining mark is not replaced with a precomposed character because the combination is blocked by normalization rules. For example, some Indic scripts do not compose certain sequences of base plus diacritic, even though a matching precomposed character exists, due to composition exclusion rules. Composition may also be blocked by another combining mark between the two characters that would otherwise combine.</p>
          </div>
          
        </section>
        <section id="normalization_forms">
          <h4>Unicode Normalization Forms</h4>
          <p>There are four Unicode Normalization Forms. Each form is named using a letter code: </p>
          <ul>
			  <li><strong>D</strong> (or NFD) stands for <em>canonical Decomposition</em>.</li>
			  <li><strong>C</strong> (or NFC) stands for <em>Composition</em>, which is canonical decomposition followed by composition.</li>
			  <li><strong>KD</strong> (or NFKD) stands for <em>Kompatibility decomposition</em> (K because the letter C is already used).</li>
			  <li><strong>KC</strong> (or NFKC) stands for compatibility decomposition followed by composition.</li>
          </ul>
            
          <aside class=example>
			<p>Having converted a resource to a sequence of Unicode characters and unescaped any escape sequences, we can finally "normalize" the Unicode texts given in the <a href="#aringExample">example</a> above. Here are the resulting sequences in each Unicode Normalization form for the <span class=uname>U+01FA</span> example given earlier. Note that there are only three distinct code point sequences between the various normalized forms (<span class=uname>U+01FA</span>, <span class=uname>U+0041 U+030A U+0301</span>, and <span class=uname>U+FF21 U+030A U+0301</span>):</p>

          <table style="border:1px solid black; vertical-align:center; table-layout:fixed; text-align:center; column-width:200px;">
			  <thead>
				 <tr>
				  <th class=tableHead>Original Codepoints</th>
				  <th class=tableHead>NFC</th>
				  <th class=tableHead>NFD</th>
				  <th class=tableHead>NFKC</th>
				  <th class=tableHead>NFKD</th>
				 </tr>
			  </thead>
          <tr>
			  <td class=b-clear>&#x01fa;</td>
			  <td class=b-clear rowspan=7>&#x01fa;</td>
			  <td class=b-clear rowspan=7>A&#x030A;&#x0301;</td>
			  <td class=b-clear rowspan=9>&#x01fa;</td>
			  <td class=b-clear rowspan=9>A&#x030A;&#x0301;</td>
          </tr>
          <tr>
          	  <td class=tableSub>U+01FA</td>
          </tr>
          <tr>
			  <td class=b-clear>&#x00C5;&#x0301;</td>
          </tr>
          <tr>
          	  <td class=tableSub>U+00C5<br>U+0301</td>
          </tr>

          <tr>
			  <td class=b-clear>&#x212B;&#x0301;</td>
          </tr>

          <tr>
          	  <td class=tableSub>U+212B<br>U+0301</td>
          </tr>
          <tr>
			  <td class=b-clear>A&#x030A;&#x0301;</td>
          </tr>
          <tr>
          	  <td class=tableSub>U+0041<br>U+030A<br>U+0301</td>
			  <td class=tableSub>U+01FA</td>
			  <td class=tableSub>U+0041<br>U+030A<br>U+0301</td>
          </tr>
          <tr>
			  <td class=b-clear>&#xFF21;&#x030A;&#x0301;</td>
			  <td class=b-clear>&#xFF21;&#x030A;&#x0301;</td>
			  <td class=b-clear>&#xFF21;&#x030A;&#x0301;</td>
          </tr>
          <tr>
			  <td class=tableSub>U+FF21<br>U+030A<br>U+0301</td>
			  <td class=tableSub>U+FF21<br>U+030A<br>U+0301</td>
			  <td class=tableSub>U+FF21<br>U+030A<br>U+0301</td>
			  <td class=tableSub>U+01FA</td>
			  <td class=tableSub>U+0041<br>U+030A<br>U+0301</td>
          </tr>          

          </table>
          </aside>  
            
           <p>Unicode Normalization reduces these (and other potential sequences
            of escapes representing the same character) to just three possible
            variations. However, Unicode Normalization doesn't remove all
            textual distinctions and sometimes the application of Unicode
            Normalization can remove meaning that is distinctive or meaningful
            in a given context. For example: </p>
          <ul>
            <li>Not all compatibility characters have a compatibility
              decomposition.</li>
            <li>Some characters that look alike or have similar semantics are actually distinct in Unicode and don't have canonical or compatibility decompositions to link them together. For example, <span class="codepoint"><span lang="zh">&#x3002;</span> [<span class="uname">U+3002 IDEOGRAPHIC FULL STOP</span>]</span> is used as a <span class="quote">period</span> at the end of sentences in languages such as Chinese or Japanese. However, it is not considered equivalent to the ASCII <span class="quote">period</span> character <span class="codepoint"><span lang="en">&#x002E;</span> [<span class="uname">U+002E FULL STOP</span>]</span>.</li>
            <li>Some character variations are not handled by the Unicode
              Normalization Forms. For example, UPPER, Title, and lowercase
              variations are a separate and distinct textual variation that must
              be separately handled when comparing text.</li>
            <li>Compatibility normalization removes meaning. For example, the character sequence <span class="qterm"><samp>8&#xbd;</samp></span> (including the character <span class="codepoint"><span lang="en">&#x00BD;</span> [<span class="uname">U+00BD VULGAR FRACTION ONE HALF</span>]</span>), when normalized using one of the <span class="quote">compatibility</span> normalization forms (that is, <code>NFKD</code> or <code>NFKC</code>), becomes an ASCII character sequence: <samp>81/2</samp>.</li>
          </ul>
        </section>
        </section>
        <section id="normalizationLimitations">
         <h3>Identical-Appearing Characters and the Limitations of Normalization</h3>
         <p>Many users are surprised to find that two identical-looking strings&mdash;including
         those that have had a specific Unicode normalization form applied&mdash;might not 
         in fact use the same underlying <a>Unicode code points</a>. This includes strings that have
         had the more-destructive <code>NFKC</code> and <code>NFKD</code> compatibility normalization
         forms applied to them. Even when strings, tokens, or identifiers appear visually to be the same, 
         they can be encoded differently.</p>
         
   		  <p>The Unicode canonical normalization forms are concerned with folding the multiple different code point sequences that can be used for a given abstract character or grapheme cluster to use the same code point sequence. However, logically distinct characters or grapheme clusters can still look the same or very similar. When a pair of <a>graphemes</a> look identical (or very similar), they are called <dfn data-lt="homograph|homographs">homographs</dfn>. When a pair of graphemes look similar or are <a>homographs</a> but actually represent logically different characters or character sequences, they are said to be <q><dfn>confusable</dfn></q>.</p>
   		  
		  <aside class="example">
		    <table>
				<tr>
					<td class="exampleChar">&#x3a1;</td>
					<td><code>U+03A1 GREEK CAPITAL LETTER RHO</code></td>
				</tr>
				<tr>
					<td class="exampleChar">&#x420;</td>
					<td><code>U+0420 CYRILLIC CAPITAL LETTER ER</code></td>
				</tr>
				<tr>
					<td class="exampleChar">P</td>
					<td><code>U+0050 LATIN CAPITAL LETTER P</code></td>
				</tr>
		    </table>
		  	<p>There are many cross-script examples, such as the characters shown above. These letters from the Greek, Cyrillic, and Latin scripts look identical in most fonts (that is, they are <a>homographs</a>), 
		    but they are encoded separately, as they are logically distinct parts of their respective Greek, Cyrillic, or Latin alphabet. Unicode Normalization will not fold these characters together.</p>
		  </aside>

		  <p>Examples of identical or identical-seeming appearance can appear even within a single script. This can take the form of similarly shaped characters, such as "0" and "O" or "l" and "1". But other scripts or the use of different compatibility characters can present much less readily distinguished variations. In some cases, Unicode Normalization brings these together, but in many other cases it does not.
		  </p> 
		  <aside class="example" title="Examples of homographs within a single script">
		  <p>Some character sequences that can sometimes appear very similar (or identical) in a single script include:</p>
		  <table>
		     <tr>
		       <td class="exampleChar">&#x8a1;</td>
		       <td class="exampleChar">&#x628;&#x654;</td>
				 <td class="exampleChar">&nbsp;</td>
		       <td><code>U+08A1 ARABIC LETTER BEH WITH HAMZA ABOVE</code> vs. <code>ARABIC LETTER BEH</code> followed by <code>ARABIC HAMZA ABOVE</code></td>
		     </tr>
		     <tr>
				 <td class="exampleChar">&#x133;</td>
				 <td class="exampleChar">ij</td>
				 <td class="exampleChar">&nbsp;</td>
				 <td><code>U+0133 LATIN SMALL LIGATURE IJ</code> vs. <code>LATIN SMALL LETTER I</code> + <code>LATIN SMALL LETTER J</code></td>
		     </tr>
		     <tr>
				 <td class="exampleChar">&#x1780;&#x17d2;&#x178f;</td>
				 <td class="exampleChar">&#x1780;&#x17d2;&#x178a;</td>
				 <td class="exampleChar">&nbsp;</td>
				 <td>Khmer sequences involving <code>U+17D2 KHMER SIGN COENG</code> such as <code>U+17D2 U+178F</code>
		    and <code>U+17D2 U+178A</code> (each shown here, for legibility, with the
		    base character <code>U+1780 KHMER LETTER KA </code> &#x1780;)</td>
		     </tr>
		  </table>
		  </aside>
		  <p>Characters that are identical or <q>confusable</q> in appearance can present spoofing and 
		  other security risks. This can be true within a single script or for similar characters in 
		  separate scripts. For further discussion and examples of homoglyphs and confusability,
		  one useful reference is [[UTS39]].</p>
		  <p>In addition to identical or similar-appearing characters, the opposite problem also exists: 
		  Unicode Normalization, even the <code>NFKC</code> and <code>NFKD</code> Compatibility forms,
		    does not bring together characters that have the same intrinsic meaning or function
		    but which vary in appearance or usage. For example, <code>U+002E</code> (.) 
		    and <code>U+3002</code> (&#x3002;) both function as sentence ending punctuation, 
		    but the distinction is not removed by normalization because the characters have a distinct identity.
		  </p>


      </section>
              
      <section id="normalizationAndCasefold">
		<h3>Interaction of Normalization and Case Folding</h3>
		
		<p>When matching strings in a case-insensitive manner, one complication is that the case folding process can produce strings that are not normalized, even if the original string was normalized. Since string comparison relies on matching code point sequences, each case folded string must be normalized if the matching process is to be reliable.</p>
		
		<aside class=example>
			<p>The most common cases are characters that have a canonical mapping or whose case-folded character sequence has a canonical mapping. For example:</p>
			<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>Normalized</th>
				</tr>
				
				<tr>
					<td class=exampleChar>&#x1FC9;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f73;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>&#x03ad;</td>
				</tr>
				<tr>
					<td><code>U+1FC9</code></td>
					<td></td>
					<td><code>U+1F73</code></td>
					<td></td>
					<td><code>U+03AD</code></td>
				</tr>
				                
                <tr>
					<td class=exampleChar>&#x95a;</td>
					<td>=></td>
					<td class=exampleChar>&#x95a;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>&#x917;&#x93c;</td>					
                </tr>
                <tr>
					<td><code>U+095A</code></td>
					<td></td>
					<td><code>U+095A</code></td>
					<td></td>
					<td><code>U+0917 U+093C</code></td>
                </tr>
			</table>
		
		<p>More commonly, though, the connection between normalization and case folding has to do with ensuring that strings which use combining marks reorder or recombine in the same way for comparison purposes:</p>
		

			<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>Normalized</th>
				</tr>
                <tr>
					<td class=exampleChar>Q&#x307;&#x323;</td>
					<td>=></td>
					<td class=exampleChar>q&#x307;&#x323;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>q&#x323;&#x307;</td>					
                </tr>
                <tr>
					<td><code>U+0051 U+0307 U+0323</code></td>
					<td></td>
					<td><code>U+0071 U+0307 U+0323</code></td>
					<td></td>
					<td><code>U+0071 U+0323 U+0307</code></td>
                </tr>

                <tr>
					<td class=exampleChar>&#xc5;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#xe5;&#x301;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>&#x1fb;</td>					
                </tr>
                <tr>
					<td><code>U+00C5 U+0301</code></td>
					<td></td>
					<td><code>U+00E5 U+0301</code></td>
					<td></td>
					<td><code>U+01FB</code></td>
                </tr>
			</table>

		
		<p>Finally, there are cases like the below, in which the case fold results in a decomposed sequence:</p>
		
			<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>Normalized</th>
				</tr>
                <tr>
					<td class=exampleChar>&#x1f0;</td>
					<td>=></td>
					<td class=exampleChar>j&#x030c;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>&#x1f0;</td>					
                </tr>
                <tr>
					<td><code>U+01F0</code></td>
					<td></td>
					<td><code>U+006A U+030C</code></td>
					<td></td>
					<td><code>U+01F0</code></td>
                </tr>

                <tr>
					<td class=exampleChar>&#x1e97;</td>
					<td>=></td>
					<td class=exampleChar>t&#x308;</td>
					<td>&#x2260;</td>
					<td class=exampleChar>&#x1e97;</td>					
                </tr>
                <tr>
					<td><code>U+1E97</code></td>
					<td></td>
					<td><code>U+0074 U+0308</code></td>
					<td></td>
					<td><code>U+1E97</code></td>
                </tr>

			</table>
		</aside>
		
		<p>The Unicode canonical normalization forms (NFC or NFD) and case folding, when used together, are closed: once a string has been case folded and then had NFD or NFC applied to it, further applications of the same case folding or Unicode normalization form do not result in a different string.</p>
		
		<p>When comparing strings for <a>compatibility equivalence</a> between characters (in other words, the NFKC/NFKD forms), the case fold-and-normalize operation must be performed twice because the compatibility decomposition step can result in characters that need to be case folded and the subsequent case fold can result in a sequence that must then be normalized.</p>
		
		<aside class=example>
			<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFKC</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFKC</th>
				</tr>
				<tr>
					<td class=exampleChar>&#x3392;</td>
					<td>=></td>
					<td class=exampleChar>&#x3392;</td>
					<td>=></td>
					<td class=exampleChar>MHz</td>
					<td>=></td>
					<td class=exampleChar>mhz</td>
					<td>=></td>
					<td class=exampleChar>mhz</td>
				</tr>
				<tr>
					<td><code>U+3392</code></td>
					<td></td>
					<td><code>U+3392</code></td>
					<td></td>
					<td><code>U+004D U+0048 U+007A</code></td>
					<td></td>
					<td><code>U+006D U+0068 U+007A</code></td>
					<td></td>
					<td><code>U+006D U+0068 U+007A</code></td>
				</tr>
				<tr>
					<td class=exampleChar>&#x2103;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#x2103;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#xb0;&#x106;</td>
					<td>=></td>
					<td class=exampleChar>&#xb0;&#x107;</td>
					<td>=></td>
					<td class=exampleChar>&#xb0;&#x107;</td>
				</tr>
				<tr>
					<td><code>U+2103 U+0301</code></td>
					<td></td>
					<td><code>U+2103 U+0301</code></td>
					<td></td>
					<td><code>U+00B0 U+0106</code></td>
					<td></td>
					<td><code>U+00B0 U+0107</code></td>
					<td></td>
					<td><code>U+00B0 U+0107</code></td>
				</tr>
				<tr>
					<td class=exampleChar>&#x03aa;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#x03ca;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#x390;</td>
					<td>=></td>
					<td class=exampleChar>&#x3b9;&#x308;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#x390;</td>
				</tr>
				<tr>
					<td><code>U+03AA U+0301</code></td>
					<td></td>
					<td><code>U+03CA U+0301</code></td>
					<td></td>
					<td><code>U+0390</code></td>
					<td></td>
					<td><code>U+03B9 U+0308 U+0301</code></td>
					<td></td>
					<td><code>U+390</code></td>
				</tr>
			</table>
		</aside>
		
		<section id="PreNormalization">
			<h4>Why does Normalization precede Case folding?</h4>
			
			<p>Unicode's definitions of <strong>canonical casefold matching</strong> (rule <code>[D145]</code>) and <strong>compatibility casefold matching</strong> (rule <code>[D146]</code>) include multiple normalization steps. This increases the complexity and cost of performing caseless matching. The initial case fold step, before performing case folding, addresses a specific corner case, which is detailed in this section.</p>
			
			<p>The concluding normalization step in Unicode's casefold matching processes exists to ensure that the resulting strings are in a specific Unicode normalization form. If the resulting case folded strings are to be stored or displayed to the user, it is a good practice to ensure that denormalized sequences produced by the case fold operation are renormalized for display. However, this step is OPTIONAL in the <a href="#CanonicalFoldNormalizationStep">Unicode Canonical Case Fold Normalization Step</a> and the <a href="#CompatibilityFoldNormalizationStep">Unicode Compatibility Case Fold Normalization Step</a>, since performing an additional normalization won't change the results of a string comparison.</p>
			
			<p>Sixty-three Greek precomposed characters have a decomposition mapping (i.e. normalize to form NFD) that contains the character &nbsp;&nbsp; <span class="codepoint" translate="no"><span lang="el">&#x0345;</span> [<span class="uname">U+0345 COMBINING GREEK YPOGEGRAMMENI</span>]</span>, a diacritical mark representing a subscripted iota (referred to as a <em>prosgegrammei</em> or <em>ypogegrammeni</em>). This mark represents an orthographic form found in ancient or classical Greek for a sound not present in more modern forms of the language. The uppercase and titlecase mappings of these characters separate this combining mark as the separate, base, letter <code>iota</code>. For consistency with title/uppercase mappings, the case fold mapping of these characters therefore contains <span class="codepoint" translate="no"><span lang="el">&#x03B9;</span> [<span class="uname">U+03B9 GREEK SMALL LETTER IOTA</span>]</span> (<a href="#definitionCaseFolding">recall</a> that Unicode case fold is generally to lower case).</p>
			
			<p>If and only if one of these 63 characters is followed by a combining mark, failing to apply canonical decomposition before case folding can result in potential comparison mismatches. Such character sequences are not in a normalized form and are difficult to produce "naturally" (through keyboards and other input processes).</p>
		
    		<p>For example, if one starts with the precomposed (NFC) character <span class="codepoint" translate="no"><span lang="el">&#x1F8C;</span> [<span class="uname">U+1F8C GREEK CAPITAL LETTER ALPHA WITH PSILI AND OXIA AND PROSGEGRAMMENI</span>]</span> (which is the most common way to represent this combination of base and diacritic characters) and just runs case fold transformations one ends up with: <span class="codepoint" translate="no"><span lang="el">&#x1F04;&#x03B9;</span> [<span class="uname">U+1F04 GREEK SMALL LETTER ALPHA WITH PSILI AND OXIA</span> + <span class="uname">U+03B9 GREEK SMALL LETTER IOTA</span>]</span>.</p>
			
			<aside class=example>
				<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFC</th>
				</tr>
				<tr>
					<td class=exampleChar>&#x1f8c;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f04;&#x03b9;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f04;&#x03b9;</td>
				</tr>
				<tr>
					<td><code>U+1F8C</code></td>
					<td></td>
					<td><code>U+1F04 U+03B9</code></td>
					<td></td>
					<td><code>U+1F04 U+03B9</code></td>
				</tr>
				</table>
			</aside>
				
			<p>If instead one starts from a fully decomposed (NFD) sequence representing the same letter, <span class="codepoint" translate="no"><span lang="el">&#x0391;&#x0313;&#x0301;&#x0345;</span> [<span class="uname">U+0391 GREEK CAPITAL LETTER ALPHA</span> + <span class="uname">U+0313 COMBINING COMMA ABOVE</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span> + <span class="uname">U+0345 COMBINING GREEK YPOGEGRAMMENI</span>]</span> one ends up with <span class="codepoint" translate="no"><span lang="el">&#x03B1;&#x0313;&#x0301;&#x03B9;</span> [<span class="uname">U+03B1 GREEK SMALL LETTER ALPHA</span> + <span class="uname">U+0313 COMBINING COMMA ABOVE</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span> + <span class="uname">U+03B9 GREEK SMALL LETTER IOTA</span>]</span>. Normalizing this string to NFC produces the same character sequence as the first example above:</p>
				
			<aside class=example>
				<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFC</th>
				</tr>
				<tr>
					<td class=exampleChar>&#x391;&#x313;&#x301;&#x345;</td>
					<td>=></td>
					<td class=exampleChar>&#x03b1;&#x0313;&#x0301;&#x03b9;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f04;&#x03b9;</td>
				</tr>
				<tr>
					<td><code>U+0391 U+0313 U+0301 U+0345</code></td>
					<td></td>
					<td><code>U+03B1 U+0313 U+0301 U+03B9</code></td>
					<td></td>
					<td><code>U+1F04 U+03B9</code></td>
				</tr>
				</table>
			</aside>
			
		
			<p>In both of those cases, the acute accent is associated with the alpha base character rather than the trailing iota.</p>

            <p>If, however, one begins with the half-precomposed sequence <span class="codepoint" translate="no"><span lang="el">&#x1F88;&#x0301;</span> [<span class="uname">U+1F88 GREEK CAPITAL LETTER ALPHA WITH PSILI AND PROSGEGRAMMENI</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span>]</span>, one ends up with <span class="codepoint" translate="no"><span lang="el">&#x1F00;&#x03B9;&#x0301;</span> [<span class="uname">U+1F00 GREEK SMALL LETTER ALPHA WITH PSILI</span> + <span class="uname">U+03B9 GREEK SMALL LETTER IOTA</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span>]</span> where the acute accent is associated with the iota. This produces a sequence that can't be normalised to match the others (and is actually incorrect, as it has a different meaning than the original user-perceived character.)</p>
            
            <aside class=example>
				<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFC</th>
				</tr>
				<tr>
					<td class=exampleChar>&#x1f88;&#x301;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f00;&#x03b9;&#x0301;</td>
					<td>=></td>
					<td class=exampleChar>&#x1f00;&#x03af;</td>
				</tr>
				<tr>
					<td><code>U+1F88 U+0301</code></td>
					<td></td>
					<td><code>U+1F00 U+03B9 U+0301</code></td>
					<td></td>
					<td><code>U+1F00 U+03AF</code></td>
				</tr>
				</table>
			</aside>

            <p>As mentioned above, Unicode solves this matching problem by normalizing the text to NFD before performing the case fold operation. Then <span class="codepoint" translate="no"><span lang="el">&#x1F8C;</span> [<span class="uname">U+1F8C GREEK CAPITAL LETTER ALPHA WITH PSILI AND OXIA AND PROSGEGRAMMENI</span>]</span> and <span class="codepoint" translate="no"><span lang="el">&#x1F88;&#x0301;</span> [<span class="uname">U+1F88 GREEK CAPITAL LETTER ALPHA WITH PSILI AND PROSGEGRAMMENI</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span>]</span> both end up the same as the decomposed version, ie. <span class="codepoint" translate="no"><span lang="el">&#x0391;&#x0313;&#x0301;&#x0345;</span> [<span class="uname">U+0391 GREEK CAPITAL LETTER ALPHA</span> + <span class="uname">U+0313 COMBINING COMMA ABOVE</span> + <span class="uname">U+0301 COMBINING ACUTE ACCENT</span> + <span class="uname">U+0345 COMBINING GREEK YPOGEGRAMMENI</span>]</span>. If one now case folds that sequence and normalizes, it produces a match for all cases:</p>
            
            <aside class=example>
				<table class=ncfExample>
				<tr>
					<th>Original</th>
					<th></th>
					<th>NFD</th>
					<th></th>
					<th>Case Fold</th>
					<th></th>
					<th>NFC</th>
				</tr>
				<tr>
					<td class=exampleChar>&#x1f8c;</td>
					<td>=></td>
					<td class=exampleChar rowspan=5>&#x0391;&#x0313;&#x0301;&#x0345;</td>
					<td rowspan=5>=></td>
					<td class=exampleChar rowspan=5>&#x03b1;&#x0313;&#x0301;&#x03b9;</td>
					<td rowspan=5>=></td>
					<td class=exampleChar rowspan=5>&#x1f04;&#x03b9;</td>
				</tr>
				<tr>
					<td><code>U+1F8C</code></td>

					<td></td>

				</tr>
				<tr>
					<td class=exampleChar>&#x391;&#x313;&#x301;&#x345;</td>
                    <td>=></td>




				</tr>
				<tr>
					<td><code>U+0391 U+0313 U+0301 U+0345</code></td>




					<td></td>

				</tr>
				<tr>
					<td class=exampleChar>&#x1f88;&#x301;</td>
                    <td>=></td>




				</tr>
				<tr>
					<td><code>U+1F88 U+0301</code></td>
                    <td></td>
					<td><code>U+0391 U+0313 U+0301 U+0345</code></td>
					<td></td>
					<td><code>U+03B1 U+0313 U+0301 U+03B9</code></td>
					<td></td>
					<td><code>U+1F04 U+03B9</code></td>
				</tr>
				</table>
			</aside>
		
		</section>

      </section>
      
      <section id="characterEscapes">
        <h3>Character Escapes and Includes</h3>
        <p>Most document formats or protocols provide an escaping mechanism to
          permit the inclusion of characters that are otherwise difficult to
          input, process, or encode. These escaping mechanisms provide an
          additional equivalent means of representing characters inside a given
          resource. They also allow for the encoding of Unicode characters not
          represented in the character encoding scheme used by the document.</p>
          
        <p class="note">For further discussion of character escapes, including guidelines for the definition of escaping mechanisms in specifications, see: <a href="https://www.w3.org/TR/charmod/#sec-Escaping">Section 4.6</a> of [[!CHARMOD]].</p>
        
        <div class="note">
              <p>The expansion of character escapes and includes is dependent on context, that is, on which <a href="#def_syntactic_content" class="termref">syntactic content</a> or programming language is considered to apply when the string matching operation is performed. Consider a search for the string <span class="qterm">suçon</span> in an XML document containing <code>su&amp;#xE7;on</code> but not <code>suçon</code>. If the search is performed in a plain text editor, the context is <span class="new-term">plain text</span> (no <a href="#def_syntactic_content" class="termref">syntactic content</a> or programming language applies), the <code class="kw">&amp;#xE7;</code> character escape is not recognized, hence not expanded and the search fails. If the search is performed in an XML browser, the context is <code>XML</code>, the character escape (defined by XML) is expanded and the search succeeds. </p>
              <p>An intermediate case would be an XML editor that <em>purposefully</em>
                provides a view of an XML document with entity references left
                unexpanded. In that case, a search over that pseudo-XML view
                will deliberately <em>not</em> expand entities: in that
                particular context, entity references are not considered
                includes and need not be expanded</p>
            </div>
        

        <p>For example, <span class="qchar">€</span> <span class="uname" translate="no">U+20AC
            EURO SIGN</span> can also be encoded in HTML as the hexadecimal
          entity <code>&amp;#x20ac;</code> or as the decimal entity <code>&amp;#8364;</code>.
          In a JavaScript or JSON file, it can appear as <code>\u20ac</code> or as <code>\u{20AC}</code>
          while in a CSS stylesheet it can appear as <code>\20ac</code>. All of
          these representations encode the same literal character value: <span class="qchar">€</span>.</p>
        <p>Character escapes are normally interpreted before a document is
          processed and strings within the format or protocol are matched.
          Returning to an example we used above: </p>
<aside class="example">
        <pre>&lt;style type="text/css"&gt;

  span.h\e9llo {
      text-decoration:underline;
  }
&lt;/style&gt;

&lt;span class="h&amp;#xe9;llo"&gt;Hello World!&lt;/span&gt;
</pre>
</aside>
        <p>You would expect that text to display like the following: <span class="héllo">Hello world!</span></p>
        
        <p>In order for this to work, the user-agent (browser) had to match two strings representing the class name <code>h&#xe9;llo</code>, even though the CSS and HTML each used a different escaping mechanism. The above fragment demonstrates one way that text can vary and still be considered "the same" according to a specification: the class name <code>h\e9llo</code> matched the class name in the HTML mark-up <code>h&amp;#xe9;llo</code> (and would also match the literal value <code>héllo</code> using the code point <span class="codepoint"><span lang="en">&#x00E9;</span> [<span class="uname">U+00E9 LATIN SMALL LETTER E WITH ACUTE</span>]</span>).</p>
        
        <p>Formal languages and document formats often offer facilities for including a piece of text from one resource inside another. An <dfn data-lt="include|includes">include</dfn> is a mechanism for inserting content into the body of a <a>resource</a>. Include mechanisms import content into a resource at processing time. This affects the structure of the document and potentially matching against the vocabulary of the document. Examples of includes are entity references in XML, the XInclude [[XInclude]] specification, and @import rules in CSS.</p>
        
        <p>An include is said to be <dfn>include normalized</dfn> if it does not begin with a combining mark (either in the form of a character escape or as a character literal in the included resource).</p>

      </section>
      <section id="invisibleCharacters">
        <h3>Invisible Unicode Characters</h3>
        <p>Unicode provides a number of special-purpose characters 
		that help document authors control the appearance or performance of 
		text. Because many of these characters are invisible or do not have keyboard equivalents, users are not always aware 
		of their presence or absence. As a result, these characters can interfere with string matching when they are part of the encoded 
		character sequence but the expected matching text does not also include them. Some examples of these characters include:</p>
          
        <p>The Unicode control characters <span class="uname" translate="no">U+200D Zero Width Joiner</span> (also known 
        as <em>ZWJ</em>) and <span class="uname" translate="no">U+200C Zero Width Non-Joiner</span> (also known as 
		  <em>ZWNJ</em>). 
		While these characters can be used to control ligature formation&mdash;either preventing the formation of undesirable 
		ligatures or encouraging the formation of desirable ones&mdash;their primary use is to control 
		  the joining and shape selection in complex scripts such as the Arabic or various of the Indic scripts. 
		  Some Indic scripts use the ZWJ and ZWNJ characters to allow authors to control the shape that certain conjuncts take. See the 
		  discussion in Chapter 12 of [[!Unicode]].</p>
		  
		<p>The <span class="uname" translate="no">Zero Width Non-Joiner</span> is used in Persian to 
		  prevent certain "normal" Arabic script joining. In these cases, the presence or absence of the
		  character <em>does</em> affect the meaning. For example, the word تنها ("alone") and the word تن‌ها&nbsp; ("bodies" 
		  or "corpuses") are encoded as "<span class="uname">U+062A 
		  U+0646 U+0647 U+0627</span>" and "<span class="uname">U+062A U+0646 
			  <span style="text-decoration:underline">U+200C</span> U+0647 U+0627</span>" 
		  respectively, the only difference being the ZWNJ in the latter word.</p>

		  <p>The ZWJ character is also used in forming certain emoji sequences, which is discussed in more
		  detail <a href="#emojiSequences">below</a>.</p>

		  <p id="variationSelectors">Variation selectors (<span class="uname">U+FE00</span> through 
		  <span class="uname" translate="no">U+FE0F</span>) are 
        characters used to select an alternate appearance or glyph 
        (see Character Model: Fundamentals [[CHARMOD]]). For example, they are used to select between black-and-white and color emoji. 
        These are also used in predefined ideographic variation sequences (<span class="qterm">IVS</span>). Many
        examples are given in the "Standardized Variants" portion of the Unicode Character Database (UCD).</p>
		  <p>A few scripts also provide a way to encode visual variation selection: a prominent example of this 
		  are the Mongolian script's free variation selectors (<span class="uname">U+180B</span> through 
		  <span class="uname" translate="no">U+180D</span>). </p>
		  <p>The character <span class="uname" translate="no">U+034F Combining Grapheme Joiner</span>, 
		  whose name is misleading (as it does not join graphemes), is used to separate characters that might otherwise be 
		  considered a grapheme for the purposes of sorting or to provide a 
		  means of maintaining certain textual distinctions when applying Unicode 
		  normalization to text. </p>
		  <p>Whitespace variations can also affect the interpretation and 
		  matching of text. For example, the various non-breaking space 
		  characters, such as NBSP, NNBSP, etc.</p>
		  <p><span class="uname" translate="no">U+200B Zero Width Space</span> is a character used to 
		  indicate word boundaries in text where spaces do not otherwise appear. 
		  For example, it might be used in a Thai language document to assist 
		  with word-breaking. </p>
		  <p>The <span class="uname" translate="no">U+00AD Soft Hyphen</span> can be used in text to indicate a potential or preferred hyphenation position. It only 
		  becomes visible when the text is reflowed to wrap at that position.</p>
		  
		  <p>The <span class="uname" translate="no">U+2060 WORD JOINER</span>, sometimes called <em>WJ</em>, is a zero-width non-breaking space character. Its purpose is to prevent line breaks between two characters. Except for purposes of line-breaking, it should be ignored. It serves as a replacement for the character <span class="uname" translate="no">U+FEFF ZERO WIDTH NO-BREAK SPACE</span> because <span class=uname translate=no>U+FEFF</span> is more commonly known as the "Byte Order Mark" (BOM). A byte order mark is used at the start of some plain text files to signal that the file is in a Unicode character encoding. </p>

        <p>Finally, most scripts, when written horizontally, proceed from left-to-right. However, some scripts, such as Arabic and Hebrew, are written predominantly from right-to-left. Texts can be written in a mix of these scripts or include character sequences, such as numbers or quotes in another script, that run in the opposite direction to other parts of the text. This intermixing of text direction is called <em>bidirectional</em> text or <q>bidi</q> for short. The Unicode Bidirectional Algorithm [[UAX9]] describes how such mixed-direction text is processed for display. For most text, the directional handling can be derived from the text itself. However, there are many cases in which the algorithm needs additional information in order to present text correctly. For more examples, see [[html-bidi]].</p>

        <p>One of the ways that Unicode defines to address the ambiguity of text direction are a set of invisible control characters to
        mark the start and end of directional runs. While bidirectional controls can have an affect on the appearance of the text
        (since they help the Unicode Bidirectional Algorithm with the presentation of text), they might have no effect on the
        text if the text would naturally have fallen into bidirectional runs without the controls. Because these controls are, like the characters mentioned above, invisible, they can have an unintentional effect on matching.
        </p>

	  <p>In almost all of these cases, users may not be aware of or cannot 
	  be sure if a given document or text string has included or omitted one 
	  of these characters. Because text matching depends on matching the 
	  underlying codepoints, variation in the encoding of the text due to 
	  these markers can cause matches that ought to succeed to mysteriously 
	  fail (from the point of view of the user).</p>

      </section>
      <section id="emojiSequences">
      <h3>Emoji Sequences</h3>   
      <p>A newer feature of Unicode are the emoji characters. In [[UTR51]], Unicode describes these as:</p>   

      <p class="quote">Emoji are pictographs (pictorial symbols) that are typically presented in a colorful cartoon 
         form and used inline in text. They represent things such as faces, weather, vehicles and buildings, 
         food and drink, animals and plants, or icons that represent emotions, feelings, or activities.</p>

      <p>Emoji can be used with a variety of emoji modifiers, including <span class="uname">U+200D ZERO WIDTH JOINER</span> or <dfn>ZWJ</dfn>, to form more complex emoji.</p>
      
      <p>For example, the emoji (<span class="codepoint"><span lang="en">&#x1F46A;</span> [<span class="uname">U+1F46A FAMILY</span>]</span>) can also be formed by using ZWJ between emoji characters in the sequence <span class="uname">U+1F468 <span style="text-decoration:underline">U+200D</span> U+1F469 <span style="text-decoration:underline">U+200D</span> U+1F466</span>.
		  Altering or adding other emoji characters can alter the composition of the family. For example the sequence 
		  <span class="uname" translate="no">&#x1f468;&#x200d;&#x1f469;&#x200d;&#x1f467;&#x200d;&#x1f467; 
		  U+1F468 U+200D U+1F469 U+200D U+1F467 U+200D U+1F467</span> results in a composed
		  emoji character for a "family: man, woman, girl, girl" on systems that support this kind of 
		  composition. Many common emoji can <em>only</em> be formed using ZWJ sequences. For more 
		  information, see [[UTR51]].</p>
		  
	  <p>Emoji characters can be followed by emoji modifier characters. These modifiers allow for the selection of skin tones for emoji that represent people. These characters are normally invisible modifiers that follow the base emoji that they modify. For example: &#x1f468;&nbsp;&#x1f468;&#x1f3fb;&nbsp;&#x1f468;&#x1f3fc;&nbsp;&#x1f468;&#x1f3fd;&nbsp;&#x1f468;&#x1f3fe;&nbsp;&#x1f468;&#x1f3ff;</p>
	     
	  <p>An emoji character can also be followed by a <a href="#variationSelectors">variation
	     selector</a> to indicate text (black and white, indicated by 
	     <span class="uname">U+FE0E Variation Selector 15</span>) or color 
	     (indicated by <span class="uname">U+FE0F Variation Selector 16</span>) presentation
	     of the base emoji.</p>
	  
	  <p>Still another wrinkle in the use of emoji are flags. National flags can be composed using country codes derived from the [[BCP47]] registry, such as the sequence <span class="codepoint"><span lang="en">&#x1F1FF;</span> [<span class="uname">U+1F1FF REGIONAL INDICATOR SYMBOL LETTER Z</span>]</span> <span class="codepoint"><span lang="en">&#x1F1F2;</span> [<span class="uname">U+1F1F2 REGIONAL INDICATOR SYMBOL LETTER M</span>]</span>, which is the country code (<kbd>ZM</kbd>) for the country Zambia: &#x1f1ff;&#x1f1f2;. Other regional or special purpose flags can be composed using a flag emoji with various symbols or with regional indicator codes terminating in a cancel tag. For example, the flag of Scotland (🏴󠁧󠁢󠁳󠁣󠁴󠁿) can be composed like this: </p>
	  <ul>
		  <li><span class="codepoint"><span lang="ang">&#x1F3F4;</span> [<span class="uname">U+1F3F4 WAVING BLACK FLAG</span>]</span>
		  <li><span class="codepoint"><span lang="ang">&#xE0067;</span> [<span class="uname">U+E0067 TAG LATIN SMALL LETTER G</span>]</span> 
		  <li><span class="codepoint"><span lang="ang">&#xE0062;</span> [<span class="uname">U+E0062 TAG LATIN SMALL LETTER B</span>]</span>
		  <li><span class="codepoint"><span lang="ang">&#xE0073;</span> [<span class="uname">U+E0073 TAG LATIN SMALL LETTER S</span>]</span> 
		  <li><span class="codepoint"><span lang="ang">&#xE0063;</span> [<span class="uname">U+E0063 TAG LATIN SMALL LETTER C</span>]</span> 
		  <li><span class="codepoint"><span lang="ang">&#xE0074;</span> [<span class="uname">U+E0074 TAG LATIN SMALL LETTER T</span>]</span> 
		  <li><span class="codepoint"><span lang="ang">&#xE007F;</span> [<span class="uname">U+E007F CANCEL TAG</span>]</span>
      </ul>
	  
 	  <p>Each of these mechanisms can be used together, so quite complex sequences of characters can be used to form a single emoji grapheme or image. Even very similar emoji sequences might not use the same exact encoded sequence. In most cases the modifiers and combinations mentioned above are generated by the end-user's keyboard (where they are presented as a single emoji "character"). This diversity of encoding options is partially addressed to the extent that different vendors use only (and exactly) the sequences that are "recommended for interchange" by Unicode. This helps vendors ensure that fonts and keyboards are prepared to give users the options they expect. Still, users generally won't be aware of the underlying encoding complexity and generative mechanisms are not limited to those that are recommended. Emoji sequences are evolving rapidly, so there could be additional developments to either help or hinder matching of emoji in the near future. Unicode normalization does not reorder these sequences or insert or remove any of the modifiers. Users and implementers are therefore cautioned that users who employ emoji characters in namespaces and other matching contexts can easily encounter unexpected "character" mismatches due to variations in encoding.</p>

      </section>
      <section id="legacyCharacterEncoding">
        <h3>Legacy Character Encodings</h3>
        <p><a>Resources</a> can use different character encoding
          schemes, including <a>legacy character encodings</a>, to serialize
          document formats on the Web. Each character encoding scheme uses
          different byte values and sequences to represent a given subset of the
          Universal Character Set.</p>
        <div class="note">
          <p><strong>Choosing a Unicode character encoding, such as UTF-8, for all documents, formats, and protocols is a strongly encouraged <a href="#convertingToCommonUnicodeForm">recommendation</a></strong>, since there is no additional utility to be gained from using a legacy character encoding and the considerations in the rest of this section would be completely avoided.</p>
        </div>
        <p>For example, <span class="codepoint"><span lang="en">&#x20AC;</span> [<span class="uname">U+20AC EURO SIGN</span>]</span> is encoded as the byte sequence <code>0xE2.82.AC</code>
          in the <code class="kw">UTF-8</code> character encoding. This same
          character is encoded as the byte sequence <code>0x80</code> in the
          legacy character encoding <code class="kw">windows-1252</code>.
          (Other legacy character encodings may not provide any byte sequence to
          encode the character.)</p>
        <p>Specifications mainly address these resulting variations by
          considering each document to be a sequence of Unicode characters after
          converting from the document's character encoding (be it a legacy
          character encoding or a Unicode encoding such as UTF-8) and then
          unescaping any character escapes before proceeding to process the
          document.</p>
        <p class="note">Even within a single legacy character encoding there can
          be variations in implementation. One famous example is the legacy
          Japanese encoding <code class="kw">Shift_JIS</code>. Different
          transcoder implementations faced choices about how to map specific
          byte sequences to Unicode. So the byte sequence <code>0x80.60</code>
          (<code>0x2141</code> in the JIS X 0208 character set) was mapped by
          some implementations to <span class="uname" translate="no">U+301C
            WAVE DASH</span> while others chose <span class="uname" translate="no">U+FF5E
            FULL WIDTH TILDE</span>. This means that two reasonable,
          self-consistent, transcoders could produce different Unicode character
          sequences from the same input. The <cite>Encoding</cite> [[Encoding]]
          specification exists, in part, to ensure that Web implementations use
          interoperable and identical mappings. However, there is no guarantee
          that transcoders consistent with the Encoding specification will be
          applied to documents found on the Web or used to process data
          appearing in a particular document format or protocol.</p>
        <p>One additional consideration in converting to Unicode is the existence of
           legacy character encodings of bidirectional scripts (such as Hebrew and Arabic) that use a
           visual storage order. That is, unlike Unicode and other modern encodings,
           the characters are stored in memory in the order that they are printed
           on the screen from left-to-right (as with a line printer). When converting
           these encodings to Unicode or when comparing text in these encodings, care
           must be taken to place both the source and target text into logical order.
           For more information, see Section 3.3.1 of [[!CHARMOD]]</p>
      </section>
      <section id="otherEquivalences">
         <h3>Other Types of Equivalence</h3>
		 
		 <p class=note>There are additional kinds of equivalence or processing that are appropriate when performing natural language searching or "find" features. These are described in another part of the Character Model series of documents ([[STRING-SEARCH]]). Specifications for a <a>vocabulary</a> or which define a matching algorithm for use in a formal syntax SHOULD avoid trying to apply additional custom folding, mapping, or processing such as described in that document, since these interfere with producing consistent, predictable results. 
		 </p>
		 
      </section>
    </section>
    <section id="identityMatching">
      <h2>String Matching of Syntactic Content in Document Formats and Protocols</h2>
      
      <p>In the Web environment, where strings can use different character encodings, use different character sequences within those encodings, and have other variations (such as case) described in this document, it's important to establish a consistent process for evaluating string identity.</p>
        
      <p>This chapter defines the requirements for specifying and implementing string matching in <a href="#def_syntactic_content" class="termref">syntactic content</a>.</p>
      
      <section id="specifying-content-restrictions">
		  <h2>Specifying Content Restrictions</h2>
		  
		  <p>One of the ways in which string matching can be made more effective and consistent is by applying restrictions to the content that is to be matched. The definition of a <a>vocabulary</a>, especially one that permits <a>user-supplied values</a> within that vocabulary, necessarily includes the rules for what makes a "valid identifier". This usually includes length and content restrictions. Some best practices for defining these restrictions include the following:</p>
		  
		  <div class="req spec" id="charmod_content_surrogates">
          <p class="advisement">Specifications SHOULD NOT allow surrogate code points (<span class=uname>U+D800</span> to <span class=uname>U+DFFF</span>) or non-character code points in identifiers.</p>
          </div>
		  
		  <div class="req spec" id="charmod_content_controls">
		  <p class="advisement">Specifications SHOULD NOT allow the <code>C0</code> (<span class=uname>U+0000</span> to <span class=uname>U+001F</span>) and <code>C1</code> (<span class=uname>U+0080</span> to <span class=uname>U+009F</span>) control characters in identifiers.</p>
          </div>
		  
		  <p>There are two broad classes of identifier: <a>user-facing identifiers</a> and <a>application internal identifiers</a>.</p>
		  
		  <p><a>Application internal identifiers</a> are the part of a document format or protocol's <a>vocabulary</a> that are machine readable and not intended for display. These are often given meaningful names (generally in English) as an affordance for developers or content authors who have to work with or debug the contents of a document format or protocol.</p>
		  
		  <div class="req spec" id="charmod_content_internal_id">
		  <p class="advisement">Specifications that define <a>application internal identifiers</a> (which are never shown to users and are always used for matching or processing within an application or protocol) SHOULD limit the content to a printable subset of ASCII. <a>ASCII case-insensitive matching</a> is RECOMMENDED.</p>
          </div>
		  
		  <div class="req spec implementation" id="charmod_content_display">
		  <p class="advisement"><a>Application internal identifier</a> fields or values MUST be wrapped with a localizable display value when displayed to end-users.</p>
          </div>
		  
		  <p><a>User-facing identifiers</a> are the part of a document format or protocol's <a>vocabulary</a> that are assigned or edited by users or presented to the user for selection. Examples of user-facing identifiers include network names (such as SSIDs); device names; class, style, or attribute names; or user-defined settings or values. Identifiers of this sort are more complex to match due to the issues described in this document, but provide the best experience, particularly for users who do not speak English or who are less familiar with the Latin script.</p>
		  
		  <p>Many <a>user-facing identifiers</a> are also <a>user-supplied values</a> and can be assigned by users of the document format or protocol. The ability to use the natural language preferred by the user or the user's community or culture provides a superior user experience and makes features more accessible to audiences that may have limited language skills, particularly in English.</p>		  
		  
		  <div class="req spec" id="charmod_content_visible">
		  <p class="advisement">When identifiers are visible or potentially visible to users, specifications SHOULD allow the use of non-ASCII Unicode characters, in order to ensure that users in all languages can use the resulting document format or protocol with equal access. Case sensitivity (i.e. no case folding) is RECOMMENDED.</p>
          </div>
		  
		  <p>While a wide range of Unicode characters ought to be permitted, specifications can still impose certain practical limits on the content of <a>user-facing identifiers</a>. One example of a specification that defines content rules of this type can be found in <cite>Unicode Identifier and Pattern Syntax</cite> [[UAX31]].</p>

      </section>
      
      <section id="choosingMatchingAlgorithm">
        <h2>Choosing a Matching Algorithm</h2>
        
        <p>The basic decision for choosing a matching algorithm to use for a given specification is the level of text normalization (which includes both case sensitivity and Unicode normalization) to apply to the strings being matched. Historically on the Web most specifications have opted for case-sensitive matching without Unicode normalization and this is the RECOMMENDED form of matching for all new specifications. However, there are cases where case-insensitivity and normalization are useful.</p>
        
        <p>A specification can choose to be case-insensitive if the benefit to users of the format or protocol in question outweighs the cost and complexity of the implementation. Because both case folding and normalization can affect the values being compared, including the presentation and, in some cases, the meaning of the text and because these operations are relatively expensive, choosing case-insensitivity is generally discouraged.</p>
        
        <p>A special case of case-insensitivity are vocabularies limited to the ASCII/Basic Latin range (that is, code points <span class=uname>U+0000</span> to <span class=uname>U+007F</span>). These specifications can choose to be case-insensitive only over that range of characters. This greatly simplifies the implementation of matching. However, this form of matching is not appropriate for specifications that allow a larger range of Unicode in identifiers or syntax, since it is difficult for users to understand the behavior of the matching and it is a disadvantage to users of non-ASCII scripts and languages. That is, users find it to be weird and unpredictable when <code class=kw>green</code> matches <code class=kw>GREEN</code> but <code class=kw>gr&#xfc;&#xdf;</code> doesn't match <code class=kw>GR&#xdc;&#x1e9e;</code> or possibly <code class=kw>GR&#xdc;SS</code> (but instead matches <code class=kw>GR&#xfc;&#xdf;</code>).</p>        
        
        <section id="matchingAlgorithm">
        <h3>The Matching Algorithm</h3>
        
        <p>The matching algorithm describes the series of steps needed to compare two strings.</p>
        
        <ol>
          <li>Convert the strings to be compared to a sequence of Unicode code points. This might entail <a href="#convertingToCommonUnicodeForm">transcoding</a> from a legacy character encoding.</li>
          <li>Expand all <a href="#expandingCharacterEscapes">character escapes and includes</a>.</li>
          <li>Perform the <a href="#performNorm">appropriate normalization step</a>.</li>
          <li>Perform any <a href="#additionalMatchTailoring">additional matching tailoring</a> specific to the specification.</li>
          <li>Compare the resulting sequences of code points for identity.</li>
        </ol>
        
        </section>
        <p></p>
        

      <section id="performNorm">
        <h4>Performing the Appropriate Normalization Step</h4>
        
        <aside class=note>
			<p>In this section, the term <em>normalization</em> is given its "usual" (non-Unicode) meaning: the application of various steps that remove variation from data. Unicode normalization forms are referred to explicitly to try to avoid confusion.</p>
        </aside>
        
        <p>The right text normalization for a given specification depends on requirements in the format or protocol's vocabulary. There are four choices for text normalization:</p>
        <ol>
			<li><strong>Default.</strong> This normalization step has no effect on the text and, as a result, is sensitive to form differences involving both case and Unicode normalization.</li>
			<li><strong>ASCII Case Fold.</strong> Comparison of text with the characters case folded in the ASCII (Basic Latin, <span class=uname>U+0000</span> to <span class=uname>U+007F</span>) range.</li>
			<li><strong>Unicode Canonical Case Fold.</strong> Comparison of text that is both case folded and has Unicode canonical normalization applied.</li>
			<li><strong>Unicode Compatibility Case Fold.</strong> Comparison of text that is both case folded and has Unicode <em>compatibility</em> normalization applied.</li>
        </ol>
        
        <section id="DefaultNormalizationStep">
			<h5>Default Normalization Step</h5>
               
            <div class="req spec" id="matching_DefaultNormalizationStep">
            <p class="advisement">It is RECOMMENDED to do NO case folding or Unicode Normalization of content when matching strings in identifiers and syntactic content.</p>
            </div>
        
			
			<p>This normalization step has no effect on the text and, as a result, comparisons are sensitive to both case and Unicode normalization form differences in the source strings being compared. Content authors need to be aware of, and ensure that they use, consistent case and consistent character sequences to encode affected text if they expect  tokens to match.</p>
        </section>
        
        <section id="ASCIIFoldNormalizationStep">
			<h5>ASCII Case Fold Normalization Step</h5>
               
            <div class="req spec" id="matching_ASCIIFoldNormalizationStep">
            <p class="advisement">An <a class="termref" href="#ASCIIFoldNormalizationStep">'ASCII case fold'</a> approach should only be used in exceptional cases, for  vocabularies that are themselves limited to the ASCII range (or where matching only occurs on the ASCII tokens).</p>
            </div>
        
			
			<p>The ASCII Case Fold normalization step performs case folding only of the ASCII range.  No Unicode normalization form is applied. This step is only appropriate for vocabularies that are themselves limited to the ASCII range (or where matching only occurs on the ASCII tokens).</p>
			
			<aside class=example>
				<p>Examples of strings that match each other in ASCII Case Fold but not in default:</p>
<pre>
hello
Hello
HELLO
hElLo
</pre>
				
				<p>Examples of strings that do not match each other in ASCII Case Fold (or any of the strings just above):</p>
<pre>
H&#xc9;LLO
h&#xe9;llo
HELL&#xd6;
HE&#x141;&#x141;O
</pre>
			</aside>
			
			<p>For each string, perform the following steps:</p>
			<ol>
				<li>For each Unicode code point in the string, if the code point is between <span class=uname translate=no>U+0041 LATIN CAPITAL LETTER A</span> and <span class=uname translate=no>U+005A LATIN CAPITAL LETTER Z</span> inclusive, replace it with the corresponding code point between <span class=uname translate=no>U+0061 LATIN LOWERCASE LETTER A</span> and <span class=uname translate=no>U+007A LATIN LOWERCASE LETTER Z</span>, otherwise retain the original code point.</li>
				<li>Return the resulting string.</li>
			</ol>
        </section>
        
        <section id="CanonicalFoldNormalizationStep">
			<h5>Unicode Canonical Case Fold Normalization Step</h5>
               
        <div class="req spec" id="matching_CanonicalFoldNormalizationStep">
            <p class="advisement">Case sensitivity is not recommended for most specifications but, in the case of an exception  where the vocabulary allows non-ASCII characters  and which does not want to be sensitive to case distinctions, the <a href="#CanonicalFoldNormalizationStep" class="termref">'Unicode canonical case fold'</a> approach SHOULD  be used.</p>
        </div>
        
			
			<p>Specifications that have <a>vocabularies</a> that allow non-ASCII characters should include most new vocabularies.</p>
			
			<p>Unicode case folding can produce denormalized character sequences, so, in order matching to be consistent with user expectations, any Unicode case fold needs to be followed by Unicode normalization. See <a href="#normalizationAndCasefold"></a> for examples.</p>
			
			<p class=note>[[Unicode]] requirement <kbd>D145</kbd> requires a normalization step following the case fold operation to ensure that the resulting strings are in a normalized form. Inclusion of the post-case fold normalization is <a href="#PreNormalization">optional</a>. If the resulting strings are only for comparison and not stored or shown to the user, the code point sequences will be equivalent following the case fold. They just aren't guaranteed to be in any specific normalization form. This is a WILLFUL VIOLATION of <kbd>D145</kbd>. Unicode has confirmed that this is a valid recommendation.</p>
			
			<p>For each string, perform the following steps: </p>
			
			<ol>
				<li>Perform Unicode normalization of the string to form NFD <strong><em>or</em></strong> form NFC.</li>
				<li>Perform <a>Unicode Full</a> case folding of the resulting string.</li>
				<li>[<strong>OPTIONAL</strong>] Perform Unicode normalization of the resulting string to form NFC. This ensures that the strings are in a normalized form for display to the user.</li>
				<li>Return the result.</li>
			</ol>
        </section>
        
        <section id="CompatibilityFoldNormalizationStep">
			<h5>Unicode Compatibility Case Fold Normalization Step</h5>
               
            <div class="req spec" id="matching_CompatibilityFoldNormalizationStep">
            <p class="advisement">A <a href="#CompatibilityFoldNormalizationStep" class="termref">'Unicode compatibility case fold'</a> approach should not be used.</p>
            </div>
        
			
			<p>Specifications that have vocabularies that allow non-ASCII characters and which need to match Unicode compatibility equivalents might use this normalization step. Because the compatibility normalization forms (<kbd>NFKC</kbd> and <kbd>NFKD</kbd>) change the meaning, appearance, and processing of the text, this step SHOULD NOT be used for most applications on the Web.</p>
			
			<aside class=warning>
				<p>Unicode compatibility decomposition removes meaning from the text that it is applied to. That means that this normalization step produces the most promiscuous matches. Some developers and specification authors find this level of normalization attractive because it appears to bring together many strings that are logically similar, but this level of normalization has limited utility in actual practice and has side effects that confuse users. This normalization step is presented for completeness, but it is not generally appropriate for use on the Web.</p>
			</aside>
			
			<p>Case folding is affected by the input code point sequence. It can also produce a denormalized code point sequence. The interaction of compatibility decomposition with case folding requires multiple passes to produce a consistent match. As a result, this normalization step includes multiple uses of Unicode normalization. See <a href="#normalizationAndCasefold"></a> for examples.</p>
			
			<p>For each string, perform the following steps: </p>
			
			<ol>
				<li>Perform Unicode normalization of the string to form NFD <strong><em>or</em></strong> perform mapping of the 63 affected Greek characters.</li>
				<li>Perform <a>Unicode Full</a> case folding of the resulting string.</li>
				<li>Perform Unicode normalization of the resulting string to form NFKD.</li>
				<li>Perform <a>Unicode Full</a> case folding of the resulting string. (This eliminates artifacts produced by the compatibility mapping.)</li>
				<li>[<strong>OPTIONAL</strong>] Perform Unicode normalization of the resulting string to form NFKC. (This ensures that the code point sequence is normalized for display.)</li>
				<li>Return the result.</li>
			</ol>
        </section>
      </section>
        

      <section id="convertingToCommonUnicodeForm">
        <h4>Converting to a Sequence of Unicode Code Points</h4>

	    <div class="req content" id="practice-useUTF-8">
        <p class="advisement">Content authors SHOULD enter and store resources in a Unicode character encoding (generally UTF-8 on the Web).</p>
        </div>
        
        <p>The first step in comparing text is to ensure that both use the same digital representation. This means that implementations need to convert any text in a <a>legacy character encoding</a> to a sequence of Unicode code points. Normally this is done by applying a <a>transcoder</a> to convert the data to a consistent Unicode encoding form (such as UTF-8 or UTF-16). This allows bitwise comparison of the strings in order to determine string equality.</p> 
        
	    <div class="req content" id="practice-normalizingTranscoder">
        <p class="advisement">Content authors SHOULD choose a <a>normalizing transcoder</a> when converting legacy encoded text or resources to Unicode unless the mapping of specific characters interferes with the meaning.</p>
        </div>
        
        <p>A <dfn>normalizing transcoder</dfn> is a <a>transcoder</a> that performs a conversion from a <a>legacy character encoding</a> to Unicode <em>and</em> ensures that the result is in Unicode Normalization Form C (NFC). For most legacy character encodings, it is possible to construct a normalizing transcoder (by using any transcoder followed by a normalizer); it is not possible to do so if the <a>legacy character encoding</a>'s <a href="https://www.w3.org/TR/2005/REC-charmod-20050215/#def-repertoire">repertoire</a> contains characters not represented in Unicode. While normalizing transcoders only produce character sequences that are in NFC, the converted character sequence might not be <a>include normalized</a> (for example, if it begins with a combining mark).</p>
        
        <p>Because document formats on the Web often interact with or are processed using additional, external resources (for example, a CSS style sheet being applied to an HTML document), the consistent representation of text becomes important when matching values between documents that use different character encodings. Use of a normalizing transcoder helps ensure interoperability by making legacy encoded documents match the normally expected Unicode character sequence for most languages.</p>
        
        <p>Most transcoders used on the Web produce NFC as their output, but several do not. This is usually to allow the transcoder to be round-trip compatible with the source legacy character encoding, to preserve other character distinctions, or to be consistent with other transcoders in use in user-agents. This means that the Encoding specification [[!Encoding]] and various other important transcoding implementations include a number of non-normalizing transcoders. Indeed, most compatibility characters in Unicode exist solely for round-trip conversion from legacy encodings and a number of these have singleton canonical mappings in NFC. You saw an example of this <a href="#unicodeNormalization">earlier in the document</a> with <span class="codepoint"><span lang="en">&#x212B;</span> [<span class="uname">U+212B ANGSTROM SIGN</span>]</span>.</p> 
        
                
        <p>Bear in mind that most transcoders produce NFC output and that even those transcoders that do not produce NFC for all characters produce NFC for the preponderance of characters. In particular, there are no commonly-used transcoders that produce decomposed forms where precomposed forms exist or which produce a different combining character sequence from the normalized sequence (and this is true for <em>all</em> of the transcoders in [[!Encoding]]).</p>
               
	    <div class="req spec" id="practice-allowUnicode">
        <p class="advisement">Specifications MUST allow a Unicode character encoding.</p>
        </div>
        
	    <div class="req spec" id="practice-defaultEncoding">
        <p class="advisement">Specifications MUST specify a default character encoding and SHOULD specify UTF-8 as the default encoding.</p>
        </div>
        
	    <div class="req spec" id="practice-disallowLegacy">
        <p class="advisement">Specifications SHOULD disallow encodings other than UTF-8.</p>
        </div>

        <p><a>Legacy character encodings</a> have generally outlived their usefulness on the Web. New specifications need to support Unicode encodings from the beginning, default to a Unicode encoding (generally UTF-8), and, if at all possible, disallow any other encodings to be used. This not only promotes interoperability, but reduces the range of pointless variation in character and data representation.</p>
        
        </section>
        
        <section id="expandingCharacterEscapes">
        <h4>Expanding Character Escapes and Includes</h4>
        <p>Most document formats and protocols provide a means for encoding characters as an escape sequence or including external data, including text, into a  <a>resource</a>. This is discussed in detail in Section 4.6 of [[!CHARMOD]]  as well as <a href="#characterEscapes">above</a>.</p>
		
		<p>When performing matching, it is important to know when to interpret character escapes so that
		   a match succeeds (or fails) appropriately. Normally, escapes, references, and includes are processed
		   or expanded before performing matching (or match-sensitive processing), since these syntaxes exist to allow difficult-to-encode
		   sequences to be put into a document conveniently, yet allowing the characters to behave as-if they were
		   directly encoded as a codepoint sequence in the document in question.</p>
		 <p>One area where this can be complicated is deciding how <a>syntactic content</a> and <a>localizable content</a> interact.
		 For example, consider the following snippet of HTML:</p>
		 <aside class="example">
		 <pre>
&lt;p id="&amp;#x300;"&gt;Combining mark used as the value of 'id' attribute&lt;p&gt;
		 </pre>
		 </aside>
		 <p>Although technically the combining mark <span class="codepoint"><span lang="en">&nbsp;&#x0300;</span> [<span class="uname">U+0300 COMBINING GRAVE ACCENT​</span>]</span> combines with the preceding quote mark, HTML does not consider the character (whether or not it is encoded as an entity) to form part of the HTML syntax.</p>
		 
		  <p>When performing a matching operation on a resource, the general rule is to expand escapes on the same &quot;level&quot; as the user is  interacting with. For example, when considering the above example, a tool to view the source of the HTML would show the escape sequence <code>&amp;#x300;</code> as a string of characters starting with an ampersand. A JavaScript program, by contrast, operates on the browser's interpretation of the document and would match the character <code>U+0300</code> as the value of the attribute <code>id</code>.</p>
		  
		  <p>When processing the syntax of a document format, escapes are usually converted to the character sequence they represent before the processing of the syntax, except where explicitly forbidden by the format's processing rules. This allows resources to include characters of all types into the resource's syntactic structures.</p>
		  
		  <p>In some cases, pre-processing escapes creates problems. For example, expanding the sequence <code>&amp;lt;</code> before parsing an HTML document would produce document errors.</p>
      </section>
        <section id="normalizationChoice">
          <h4>Additional Considerations for Normalization</h4>
          
          <p>A specific Unicode normalization form is not always appropriate or available to content authors and the text encoding choices of users might not be obvious to downstream consumers of the data. As shown in this document, there are many different ways that content authors or applications could choose to represent the same semantic values when inputting or exchanging text. Normalization can remove distinctions that the users applied intentionally. Therefore, the <a href="#matchingAlgorithm">matching algorithm</a> specifies the use of Unicode normalization when performing case-fold matching of strings&mdash;and then only internally to the algorithm. Imposing normalization on content can represent a barrier to users and implementers. Thus:</p>
      
	      <div class="req spec" id="charmod_n11n_should_not">
          <p class="advisement">Specifications SHOULD NOT specify a Unicode normalization form for encoding, storage, or interchange of a given vocabulary.</p>
          </div>
          
	      <div class="req implementation" id="charmod_n11n_must_not">
          <p class="advisement">Implementations MUST NOT alter the normalization form of syntactic content (including user-supplied values) or localizable content being exchanged, read, parsed, or processed except when required to do so as a side-effect of text transformation such as transcoding the content to a Unicode character encoding, case folding, or other user-initiated change, as consumers or the content itself might depend on the de-normalized representation.</p>
          </div>
          
	      <div class="req implementation" id="charmod_n11n_authoring">
          <p class="advisement">Authoring tools SHOULD provide a means of normalizing resources and warn the user when a given resource is not in Unicode Normalization Form C.</p>
          </div>
          
          <p class=note>A specification that requires storage and interchange of text in a specific normalization form needs to address the requirements in <a href="#normalizing-spec"></a>.</p>
       
          <p>Specifications are generally discouraged from requiring formats or protocols to store or exchange data in a normalized form unless there are specific, clear reasons why the additional requirement is necessary. As many document formats on the Web do not require normalization, content authors might occasionally rely on denormalized character sequences. A normalization step could negatively affect such content.</p>
          
          <p>The canonical normalization forms (form NFC or form NFD) are intended to preserve the meaning and presentation of the text to which they are applied. This is not always the case, which is one reason why normalization is not recommended. NFC has the advantage that almost all legacy data (if transcoded trivially, one-to-one, to a Unicode encoding), as well as data created by current software or entered by users on most (but not all) keyboards, is already in this form. NFC also has a slight compactness advantage and is a better match to user expectations in most languages with respect to the relationship between characters and graphemes.</p>
          
	      <div class="req spec" id="charmod_n11n_compat">
          <p class="advisement">Specifications SHOULD NOT specify compatibility normalization forms (NFKC, NFKD).</p>
          </div>
          
	      <div class="req implementation" id="charmod_n11n_compat_impl">
          <p class="advisement">Implementations MUST NOT apply compatibility normalization forms (NFKC, NFKD) unless specifically requested by the end user.</p>
          </div>
          
          <p>The compatibility normalization forms (form NFKC and form NFKD) change the structure and lose the meaning of the text in important ways. Users sometimes use characters with a compatibility mapping in Unicode on purpose or they use characters in a legacy character encoding that have a compatibility mapping when converted to Unicode. This has to be considered intentional on the part of the content author. Although NFKC/NFKD can sometimes be useful in "find" operations or string searching localizable content, erasing compatibility differences is harmful.</p>

          <p class=note>Requiring NFC requires additional care on the part of the specification developer, as content on the Web generally is not in a known normalization state. Boundary and error conditions for denormalized content need to be carefully considered and well-specified in these cases. </p>
          
	      <div class="req spec" id="charmod_n11n_health_warning">
          <p class="advisement">Specifications MUST document or provide a health-warning if canonically equivalent but disjoint Unicode character sequences represent a security issue.</p>
          </div>
          
          <div class="req content" id="charmod_n11n_nfc">
          <p><span class="advisement">Content authors SHOULD use Unicode Normalization Form C (NFC) wherever possible for content.</span> 
           </div>
         
          <p>Note that NFC is not always appropriate to the content or even available to content authors in some languages.</p>
          
          <div class="req content" id="charmod_n11n_consistency">
          <p class="advisement">Content authors SHOULD always encode text using consistent Unicode character sequences to facilitate matching, even if a Unicode normalization form is included in the matching performed by the format or implementation.</p>
          </div>
          
          <p>In order for their content to be processed consistently, content authors should try to use a consistent sequence of code points to represent the same text. While content can be in any normalization form or might use a de-normalized (but valid) Unicode character sequence, inconsistency of representation will cause implementations to treat the different sequences as different. The best way to ensure consistent selection, access, extraction, processing, or display is to always use NFC. </p>
          
          <div class="req content" id="charmod_n11n_combining_marks">
          <p class="advisement">Content authors SHOULD NOT include combining marks without a preceding base character in a resource.</p>
          </div>

          <p>There can be exceptions to this. For example, when making a list of characters (such as a list of [[!Unicode]] characters), an author might want to use combining marks without a corresponding base character. However, use of a combining mark without a base character can cause unintentional display or processing problems, such as when a na&#xef;ve implementation combines the combining mark with adjacent syntactic, user-supplied, or localizable content. For example, if you were to use  a combining mark, such as the character <span class="codepoint"><span lang="en">&nbsp;&#x0301;</span> [<span class="uname">U+0301 COMBINING ACUTE ACCENT​</span>]</span>, as the start of a <code>class</code> attribute value in HTML, the class name might not display properly in your editor and be difficult to edit.</p>
          
          <p>Some recommended base characters include <span class="codepoint"><span lang="en">&#x25CC;</span> [<span class="uname">U+25CC DOTTED CIRCLE</span>]</span> (when the base character needs to be visible) or <span class="codepoint"><span lang="en">&#x00A0;</span> [<span class="uname">U+00A0 NO-BREAK SPACE</span>]</span> (when the base character should be invisible).</p>
          
          <p>Since content authors do not always follow these guidelines:</p>
          
          <div class="req spec" id="charmod_n11n_boundaries">
          <p class="advisement">Specifications of vocabularies MUST define the boundaries between syntactic content and character data as well as entity boundaries (if the language has any include mechanism).</span> These need to include any boundary that may create conflicts when processing or matching content when instances of the language are processed, while allowing for character escapes designed to express arbitrary characters.</p>
          </div>
          
        <section id="normalizing-spec">
			
          <h4>Requirements When Specifying Normalization in Document Formats</h4>
          
          <p>When a specification requires Unicode normalization for storage, transmission, or processing, some additional considerations need to be addressed by the specification authors as well as by implementers of that specification:</p>
          
          <div class="req spec" id="charmod_n11n_define">
          <p class="advisement">Where operations can produce denormalized output from normalized text input, specifications MUST define whether the resulting output is required to be normalized or not. Specifications MAY state that performing normalization is optional for some operations; in this case the default SHOULD be that normalization is performed, and an explicit option SHOULD be used to switch normalization off.</p>
          </div>
          
          <div class="req spec" id="charmod_n11n_non_optional">
          <p class="advisement">Specifications that require normalization MUST NOT make the implementation of normalization optional.</p>
          </div>
          
          <p>Interoperability cannot be achieved if some implementations normalize while others do not.</p>
          <p>An implementation that is required to perform normalization needs to consider these requirements:</p>

          <div class="req implementation" id="charmod_n11n_confirm">
          <p class="advisement">Normalization-sensitive operations MUST NOT be performed unless the implementation has first either confirmed through inspection that the text is in normalized form or it has re-normalized the text itself. Private agreements MAY be created within private systems which are not subject to these rules, but any externally observable results MUST be the same as if the rules had been obeyed.</p>
          </div>

          <div class="req implementation" id="charmod_n11n_modification">
          <p class="advisement">A normalizing text-processing component which modifies text and performs normalization-sensitive operations MUST behave as if normalization took place after each modification, so that any subsequent normalization-sensitive operations always behave as if they were dealing with normalized text. </p>
          </div>

          <div class="req implementation" id="charmod_n11n_auth_tool">
          <p class="advisement">Authoring tool implementations SHOULD warn users or prevent the input or creation of syntactic content starting with a combining mark that could interfere with processing, display, or interchange.</p>
          </div>
        </section>

        </section>
        
        <section id="handlingCaseFolding">
        <h4>Additional Considerations for Case Folding</h4>
        
        <p>One important consideration in string identity matching is whether the comparison is case sensitive or case insensitive.</p>
        
        <div class="req content" id="charmod_consistent_format">
        <p class="advisement">Content authors SHOULD always spell identifiers using consistent upper, lower, and mixed case formatting to facilitate matching, even if case folded matching is supported by the format or implementation.</p>
        </div>
        
        <section id="sec_case_sensitive">
          <h4>Case-sensitive matching</h4>

          <div class="req spec" id="charmod_rec_case_sensitive">
          <p class="advisement"><a href="#case-sensitive">Case-sensitive</a> matching is RECOMMENDED for matching syntactic content, including user-defined values.</p>
          </div>

          <p>Vocabularies usually put a premium on predictability for content authors and users. Case-sensitive matching is the easiest to implement and introduces the least potential for confusion, since it generally consists of a comparison of the underlying Unicode code point sequence. Because it is not affected by considerations such as language-specific case mappings, it produces the least surprise for document authors that have included words, such as the <a href="#caseMappingLanguageSensitivity">Turkish examples</a> above, in their syntactic content.</p>
        
          <p>Case insensitivity is usually reserved for processing <a>localizable content</a>, such as performing a <a>natural language</a> textual search. However, sometimes case-insensitivity is desirable. In this cases there are several implementation choices that a formal language needs to consider. </p>
       </section>
       <section id="sec_unicode_cs">
          <h4>Unicode case-insensitive matching</h4>
          
          <div class="req spec" id="charmod_full_case_fold">
          <p class="advisement">Specifications that define case-insensitive matching in vocabularies that include more than the Basic Latin (ASCII) range of Unicode MUST specify <a href="#uci">Unicode full</a> casefold matching.</p>
          </div>
           
          <div class="req spec" id="charmod_unicode_full_range">
          <p class="advisement">Specifications SHOULD allow the full range of Unicode for user-defined values.</p>
          </div>
          
          <p>Vocabularies generally should allow for a wide range of Unicode characters, particularly for <a>user-supplied values</a>, so as to enable use by the broadest range of languages and cultures without disadvantage. As a result, text operations such as case folding need to address the full range of Unicode and not just selected portions. When case-insensitive matching is desired, this means using <a href="#definitionCaseFolding">Unicode case folding</a>:</p>

          <p>The <a>Unicode simple</a> casefolding form is not appropriate for string identity matching on the Web.</p>

        </section>
        <section id="sec_ascii_cs">
          <h4>ASCII case-insensitive matching</h4>
 
         <div class="req spec" id="charmod_ascii_insensitive">
         <p class="advisement">Specifications that define case-insensitive matching in vocabularies limited to the Basic Latin (ASCII) subset of Unicode MAY specify <a href="#aci">ASCII case-insensitive</a> matching.</p>
         </div>
         
         <p>A formal language whose <a>vocabulary</a> is limited to ASCII and which does not allow user-defined names or identifiers can specify <a>ASCII case-insensitive</a> matching. An example of this is HTML, which defines the use of ASCII case-insensitive comparison for element and attribute names defined by the HTML specification.</p>
         
         <p>A vocabulary is considered to be "ASCII-only" if and only if all tokens and identifiers are defined by the specification directly and these identifiers or tokens use only the Basic Latin subset of Unicode. If user-defined identifiers are permitted, the full range of Unicode characters (limited, as appropriate, for security or interchange concerns, see [[UTR36]]) should be allowed and Unicode case insensitivity used for identity matching.</p>
        
         <p class=note>An ASCII-only vocabulary can exist inside a document format or protocol that allows a larger range of Unicode in identifiers or values. For example [[CSS-SYNTAX-3]] defines the format of CSS style sheets in a way that allows the full range of Unicode to be used for identifiers and values. However, CSS specifications always define CSS keywords using a subset of the ASCII range. The vocabulary of CSS is thus ASCII-only, even though many style sheets contain identifiers or data values that are not ASCII.</p>
        </section>
        
        <section id="sec_language_tailoring">
          <h4>Language-specific tailoring</h4>
          
          <p>Locale- or language-specific tailoring is most appropriate when it is part of natural language processing operations (which is beyond the scope of this document). Because language-specific tailoring of case mapping or case folding produces different results from the generic case folding rules, these should be avoided in formal languages, where predictability is at a premium.</p>
          
          <div class="req spec" id="charmod_lang_tailoring_insensitive">
          <p class="advisement">Specifications that define case-insensitive matching in vocabularies SHOULD NOT specify language-sensitive case-insensitive matching.</p>
          </div>
          
          <div class="req spec" id="charmod_lang_tailoring_sensitive">
          <p class="advisement">If language-sensitive case-sensitive matching is specified, Unicode case mappings SHOULD be tailored according to language and the source of the language used for each tailoring MUST be specified.</p>
          </div>
          
          <p>Two strings being matched can be in different languages and might appear in yet a third language context. Which language to use for case folding therefore depends on the application and user expectations.</p>

          <p>Language specific tailoring is not recommended for formal languages because the language information can be hard to obtain, verify, or manage and because the resulting operations can produce results that frustrate users or which fail for some users and succeed for others depending on the language configuration that they are using or the configuration of the system where the match is performed.</p>
          
          <div class="req spec" id="charmod_lang_tailoring_case_fold">
          <p class="advisement">Operations that are language-specific SHOULD include language-specific case folding where appropriate.</p>
          </div>
          
          <p>For example, the CSS operation <code>text-transform</code> is language-sensitive when used to case map strings.</p>
        
          <p class=note>Although Unicode case folding is the preferred case-insensitive matching for document formats and protocols, content authors and users of languages that have mappings different from the default can still be surprised by the results, since their expectations are generally consistent with the languages that they speak.</p>
        
          <p class=note>Language-sensitive string comparison is often referred to as being <em>locale-sensitive</em>, since most programming languages and operating environments access language-specific tailoring using their respective locale-based APIs. For example, see the <code>java.text.Collator</code> class in the Java programming language or <code>Intl.Collator</code> in JavaScript.</p>

        </section>
      </section>
      
      <section id="additionalMatchTailoring">
      <h2>Additional Match Tailoring</h2>
      
      <div class="req spec" id="charmod_additional_match_tailoring">
      <p class="advisement">Specifications MUST clearly define any additional tailoring done as part of the matching process.</p>
      </div>
      
      <p>Some specifications might wish to include additional tailoring to assist with matching in a given vocabulary. Examples of this might include removing additional textual differences described in <a href="#problemStatement">Section 2</a>, mapping together or removing characters that are part of the syntax, or performing a whitespace trim.</p>
      
      <p>Any additional tailoring needs to avoid interfering with the way that different languages are represented in Unicode. For example, a process that attempts to remove accents from letters by decomposing the text and then removing all of the combining characters will break languages that rely on combining marks. An example of this would be the Devanagari text in <a href="#graphemeExample">Example 2</a>. (Such a process would also fail to remove all of the potential accents and probably do harm to the meaning and representation of the text.)</p>
      </section>
      
    </section>
        </section>
        
     <section id="otherProcessing">
	 <h2>Other Matching and Processing Considerations</h2>
		 
		 <p>While matching strings and tokens in a formal language is the primary concern of this document, sometimes a specification needs to consider additional types of matching beyond pure string equality.</p>
		 
        <section id="regularExpressions">
			<h3>Regular Expressions</h3>

            <div class="req spec" id="charmod_regular_expressions">
            <p class="advisement">Specifications that define a regular expression syntax MUST provide at least Basic Unicode Level 1 support per [[!UTS18]] and SHOULD provide Extended or Tailored (Levels 2 and 3) support.</p>
            </div>


		<p>Regular expression syntaxes are sometimes useful in defining a format or protocol, since they allow users to specify values that are only partially known or which can vary in predictable ways. As seen in the various sections of this document, there is variation in the different ways that characters can be encoded in Unicode and this potentially interferes with how strings are specified or matched in expressions. For example, counting characters might need to depend on grapheme boundaries rather than the number of Unicode code points used; caseless matching might need to consider variations in case folding; or the Unicode normalization of the expression or text being processed might need to be considered.</p>
			
			<p>Unicode Regular Expressions Level 1 support includes the ability to specify Unicode code points in regular expressions, including via the use of escapes, and to access Unicode character properties as well as certain kinds of boundaries common to most regular expression syntaxes.</p>
			
			<p>Level 2 extends this with a number of important capabilities, notably the ability to select text on certain kinds of <a>grapheme cluster</a> boundary and support for case conversion (two topics mentioned extensively above). Level 3 provides for locale [[LTLI]] based tailoring of regular expressions, which are less useful in formal languages but can be useful in processing <a>localizable content</a>.</p>

        </section>
      </section>
   
    <section class=appendix>
      <h2 id="changeLog" class="informative">Changes Since the Last Published Version</h2>
      <p>Changes to this document (beginning with the <a href="https://www.w3.org/TR/2014/WD-charmod-norm-20180420/Overview.html">Working Draft</a> of 2018-04-20) are available via the <a href="https://github.com/w3c/charmod-norm/commits/gh-pages">github commit log</a>.</p>
      
      <p>This version changes the which normalization step is optional in the <a href="#CanonicalFoldNormalizationStep">Unicode Canonical Case Fold Normalization Step</a> and the <a href="#CompatibilityFoldNormalizationStep">Unicode Compatibility Case Fold Normalization Step</a>. This version requires normalization as the first step and makes normalization of the output optional. This change is based on testing and conversation with Unicode.</p>
    </section>
    <section class=appendix>
      <h2 id="Acknowledgements" class="informative">Acknowledgements</h2>
      <!-- EDNOTE: Contributors and commenters are cited here. Please add to the list in order by family name using en-US collation rules while making allowances for the native representation of names :-)  -->
      <p>The W3C Internationalization Working Group and Interest Group, as well as others, provided many comments and suggestions. The Working Group would like to thank: 
         Mati Allouche, 
         Ebrahim Byagowi, 
         John Cowan, 
         Martin Dürst, 
         Behdad Esfahbod, 
         Asmus Freitag,
         Richard Ishida, 
         John Klensin, 
         Peter Saint-Andre, 
         Amir Sarabadani,
         Najib Tounsi,
         Richard Wordingham,
       and all of the CharMod contributors over the twenty (!!) years of this document's development. </p>
      <p>The previous version of this document was edited by:</p>
      <ul>
        <li>François Yergeau, Invited Expert (and before at Alis Technologies)</li>
        <li>Martin J. Dürst, (until Dec 2004 while at W3C)</li>
        <li>Richard Ishida, W3C (and before at Xerox)</li>
        <li>Misha Wolf, (until Dec 2002 while at Reuters Ltd.)</li>
        <li>Tex Texin, (until Dec 2004 while an Invited Expert, and before at
          Progress Software)</li>
      </ul>
    </section>

<script>
reqs = document.querySelectorAll('.req')
for (let i=0; i<reqs.length; i++) {
	if (reqs[i].id) {
		a = document.createElement('a')
		a.href = '#'+reqs[i].id
		a.textContent = '§'
		a.className = 'self-link'
		reqs[i].prepend(a)
		}
	}
</script>

</body>
</html>
